{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1) Mount drive, unzip data, clone repo, install packages\n\n## 1.1) Define paths\nGoogle Drive root: `/kaggle/working/GoogleDrive`\nDataset paths are relative to mount point (`/kaggle/input` & `/kaggle/working`).","metadata":{}},{"cell_type":"code","source":"# Create root directory if not exists\ndrive_root = '/kaggle/working/GoogleDrive'\n!mkdir -p \"$drive_root\"\n\n# Define Google Drive related paths\ndrive_root = \"/workspace/GoogleDrive\"\n!mkdir -p \"$drive_root\"\n!mkdir -p \"$drive_root/Models\"\n!mkdir -p \"$drive_root/Datasets\"\n!mkdir -p \"$drive_root/GitHub Keys\"\n\n# Define asset paths\ngit_keys_root = '/kaggle/input/git-keys/github-keys'\nassert os.path.exists(git_keys_root), f'git_keys_root={git_keys_root}: NOT FOUND'\nclient_secrets_path = '/kaggle/input/git-keys/client_secrets.json'\nassert os.path.exists(client_secrets_path), f'client_secrets_path={client_secrets_path}: NOT FOUND'","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1.2) Link inputs available via Kaggle Datasets to corresponding GoogleDrive paths","metadata":{}},{"cell_type":"code","source":"# Copy the Fonts dir inside local Google Drive root\n!cp -rf /kaggle/input/mplfonts/Fonts \"$gdrive_root\"\n\n# Link the Inceptionv3 model Checkpoint inside local Google Drive root\n!mkdir -p \"$gdrive_root\"/Models\n!cp -rf \"/kaggle/input/inception-model/model_name=inceptionv3\" \"$gdrive_root\"/Models\n!mv \"$gdrive_root\"/Models/model_name=inceptionv3/Checkpoints/1a9a5a14.pth.bak \"$gdrive_root\"/Models/model_name=inceptionv3/Checkpoints/1a9a5a14.pth\n\n# FIX: We need client_secrets.json to be writable, so copy to /kaggle/working\n!cp -f \"$client_secrets_path\" \"$gdrive_root\"\nclient_secrets_path = f'{gdrive_root}/client_secrets.json'","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1.3) Clone GitHub repo\nClone achariso/gans-thesis repo into /kaggle/working/code using git clone. For a similar procedure in Colab,\nsee: https://medium.com/@purba0101/how-to-clone-private-github-repo-in-google-colab-using-ssh-77384cfef18f","metadata":{}},{"cell_type":"code","source":"# Clean failed attempts\n!rm -rf /root/.ssh\n!rm -rf /kaggle/working/code\n!mkdir -p /kaggle/working/code\n\nrepo_root = '/kaggle/working/code/gans-thesis'\nif not os.path.exists(repo_root):\n    # Check that ssh keys exist\n    id_rsa_abs_drive = f'{git_keys_root}/id_rsa'\n    id_rsa_pub_abs_drive = f'{id_rsa_abs_drive}.pub'\n    assert os.path.exists(id_rsa_abs_drive)\n    assert os.path.exists(id_rsa_pub_abs_drive)\n    # On first run: Add ssh key in repo\n    if not os.path.exists('/root/.ssh'):\n        # Transfer config file\n        ssh_config_abs_drive = f'{git_keys_root}/config'\n        assert os.path.exists(ssh_config_abs_drive)\n        !mkdir -p ~/.ssh\n        !cp -f \"$ssh_config_abs_drive\" ~/.ssh/\n        # Add github.com to known hosts\n        !ssh-keyscan -t rsa github.com >> ~/.ssh/known_hosts\n        # Test ssh connection\n        # !ssh -T git@github.com\n\n    # Remove any previous attempts\n    !rm -rf \"$repo_root\"\n    !mkdir -p \"$repo_root\"\n    # Clone repo\n    !git clone git@github.com:achariso/gans-thesis.git \"$repo_root\"\n    src_root = f'{repo_root}/src'\n    !rm -rf \"$repo_root\"/report","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1.4) Install pip packages\nAll required files are stored in a requirements.txt files at the repository's root.\nUse `pip install -r requirements.txt` from inside the dir to install required packages.","metadata":{}},{"cell_type":"code","source":"%cd \"$repo_root\"\n!pip install -r requirements.txt","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nassert torch.cuda.is_available()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1.5) Add code/, */src/ to path\nThis is necessary in order to be able to run the modules.","metadata":{}},{"cell_type":"code","source":"content_root_abs = f'{repo_root}'\nsrc_root_abs = f'{repo_root}/src'\n%env PYTHONPATH=\"/env/python:$content_root_abs:$src_root_abs","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2) Train CycleGAN model on Bags2Shoes_64 dataset\nIn this section we run the actual training loop for CycleGAN network. CycleGAN consists of two cross-domain generators and, in our version, two PatchGAN discriminators.","metadata":{}},{"cell_type":"code","source":"chkpt_step = 'latest'  # supported: 'latest', <int>, None\nlog_level = 'debug'    # supported: 'debug', 'info', 'warning', 'error', 'critical', 'fatal'\ndevice = 'cuda'        # supported: 'cpu', 'cuda', 'cuda:<GPU_INDEX>'\n\n# Running with -i enables us to get variables defined inside the script (the script runs inline)\n%run -i src/train_setup.py --log_level $log_level --chkpt_step $chkpt_step --seed 42 --device $device -use_refresh_token","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## CycleGAN Training Setup\n\nSetup/preparation before starting CycleGAN training loop.","metadata":{}},{"cell_type":"code","source":"%cd 'src/'\n\nimport torch\nfrom IPython.core.display import display\nfrom torch import Tensor\nfrom torch.nn import DataParallel\n# noinspection PyProtectedMember\nfrom torch.utils.data import DataLoader\n\nfrom datasets.bags2shoes import Bags2ShoesDataset, Bags2ShoesDataloader\nfrom modules.cycle_gan import CycleGAN\nfrom utils.dep_free import get_tqdm\nfrom utils.ifaces import FilesystemDataset\nfrom utils.metrics import GanEvaluator\n\n# FIX\ntorch.cuda.empty_cache()\n\n###################################\n###  Hyper-parameters settings  ###\n###################################\n# TODO: finish this notebook and train in Colab/Kaggle\n#   - training\nn_epochs = 300\nbatch_size = 128 if not run_locally else 2\ntrain_test_splits = [90, 10]  # for a 90% training - 10% evaluation set split\n#   - evaluation\nmetrics_n_samples = 1000 if not run_locally else 2\nmetrics_batch_size = 32 if not run_locally else 1\nf1_k = 3 if not run_locally else 1\n#   - visualizations / checkpoints steps\ndisplay_step = 200\ncheckpoint_step = 600\nmetrics_step = 1800  # evaluate model every 3 checkpoints\n#   - dataset\ntarget_shape = 64\ntarget_channels = 3\n#   - CycleGAN configuration\nccgan_config_id = '64_MSE_L1_L1_2_9_2_9_64_3_1e4_false_false_false'  # close to DiscoGAN paper + half precision\n\n###################################\n###   Dataset Initialization    ###\n###################################\n#   - image transforms:\n#     If target_shape is different from load one, resize & crop. If target_shape is different from load shape,\n#     convert to grayscale.\n#     Update: Now done automatically if you set target_channels, target_shape when instantiating the dataloader.\ngen_transforms = Bags2ShoesDataset.get_image_transforms(target_shape=target_shape, target_channels=target_channels)\n#   - the dataloader used to access the training dataset of cross-scale/pose image pairs at every epoch\n#     > len(dataloader) = <number of batches>\n#     > len(dataloader.dataset) = <number of total dataset items>\ndataloader = Bags2ShoesDataloader(dataset_fs_folder_or_root=datasets_groot, batch_size=batch_size,\n                                  image_transforms=gen_transforms, splits=train_test_splits,\n                                  pin_memory=not run_locally, log_level=log_level)\ndataset = dataloader.dataset  # save training dataset as `dataset`\n#   - ensure dataset is fetched locally and unzipped\nif isinstance(dataset, FilesystemDataset):\n    dataset.fetch_and_unzip(in_parallel=False, show_progress=True)\nelif hasattr(dataset, 'dataset') and isinstance(dataset.dataset, FilesystemDataset):\n    dataset.dataset.fetch_and_unzip(in_parallel=False, show_progress=True)\nelse:\n    raise TypeError('dataset must implement utils.ifaces.FilesystemDataset in order to be auto-downloaded and unzipped')\n#   - apply rudimentary tests\nassert issubclass(dataloader.__class__, DataLoader)\nassert len(dataloader) == len(dataset) // batch_size + (1 if len(dataset) % batch_size else 0)\n_bags, _shoes = next(iter(dataloader))\nassert tuple(_bags.shape) == (batch_size, target_channels, target_shape, target_shape)\nassert tuple(_shoes.shape) == (batch_size, target_channels, target_shape, target_shape)\n\n###################################\n###    Models Initialization    ###\n###################################\n#   - initialize evaluator instance (used to run GAN evaluation metrics: FID, IS, PRECISION, RECALL, F1 and SSIM)\nevaluator = GanEvaluator(model_fs_folder_or_root=models_groot, gen_dataset=dataset, target_index=1, device=exec_device,\n                         condition_indices=(0,), n_samples=metrics_n_samples, batch_size=metrics_batch_size,\n                         f1_k=f1_k)\n#   - initialize model\nchkpt_step = args.chkpt_step\ntry:\n    if chkpt_step == 'latest':\n        ccgan_chkpt_step = chkpt_step\n    elif isinstance(chkpt_step, str) and chkpt_step.isdigit():\n        ccgan_chkpt_step = int(chkpt_step)\n    else:\n        ccgan_chkpt_step = None\nexcept NameError:\n    ccgan_chkpt_step = None\nccgan = CycleGAN(model_fs_folder_or_root=models_groot, config_id=ccgan_config_id, dataset_len=len(dataset),\n                 chkpt_epoch=ccgan_chkpt_step, evaluator=evaluator, device=exec_device, log_level=log_level)\nccgan.logger.debug(f'Using device: {str(exec_device)}')\nccgan.logger.debug(f'Model initialized. Number of params = {ccgan.nparams_hr}')\n# FIX: Warmup counters before first batch\nif ccgan.step is None:\n    ccgan.gforward(batch_size=batch_size)\n    ccgan.logger.debug(f'Model warmed-up (internal counters).')\n#   - setup multi-GPU training\nif torch.cuda.device_count() > 1:\n    ccgan.gen = DataParallel(ccgan.gen)\n    ccgan.info(f'Using {torch.cuda.device_count()} GPUs for CycleGAN Generator (via torch.nn.DataParallel)')\n#   - load dataloader state (from model checkpoint)\nif 'dataloader' in ccgan.other_state_dicts.keys():\n    dataloader.set_state(ccgan.other_state_dicts['dataloader'])\n    ccgan.logger.debug(f'Loaded dataloader state! Current pem_index={dataloader.get_state()[\"perm_index\"]}')\n\n# FIX: Change batch size (if needed)\nccgan.update_batch_size(batch_size, sampler_instance=dataloader.sampler)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## CycleGAN Main Training Loop\n\nStart/continue training CycleGAN until reaching the desired number of epochs.","metadata":{}},{"cell_type":"code","source":"\n# Decrease LR\nccgan.update_lr(gen_new_lr=1e-5, disc_new_lr=1e-5)\n\n###################################\n###       Training Loop         ###\n###################################\n#   - get the correct tqdm instance\nexec_tqdm = get_tqdm()\n#   - start training loop from last checkpoint's epoch and step\ntorch.cuda.empty_cache()\ngcapture_ready = True\nasync_results = None\nccgan.logger.info(f'[training loop] STARTING (epoch={ccgan.epoch}, step={ccgan.initial_step})')\nfor epoch in range(ccgan.epoch, n_epochs):\n    # noinspection PyProtectedMember\n    d = {\n        'step': ccgan.step,\n        'initial_step': ccgan.initial_step,\n        'epoch': ccgan.epoch,\n        '_counter': ccgan._counter,\n        'epoch_inc': ccgan.epoch_inc,\n    }\n    # initial_step = ccgan.initial_step % len(dataloader)\n    ccgan.logger.debug('[START OF EPOCH] ' + str(d))\n\n    bags: Tensor\n    shoes: Tensor\n    for bags, shoes in exec_tqdm(dataloader, initial=ccgan.initial_step):\n        # Transfer image batches to GPU\n        bags = bags.to(exec_device)\n        shoes = shoes.to(exec_device)\n\n        # Perform a forward + backward pass + weight update on the Generator & Discriminator models\n        disc_loss, gen_loss = ccgan(bags, shoes)\n\n        # Metrics & Checkpoint Code\n        if ccgan.step % checkpoint_step == 0:\n            # Check if another upload is pending\n            if not gcapture_ready and async_results:\n                # Wait for previous upload to finish\n                ccgan.logger.warning('Waiting for previous gcapture() to finish...')\n                [r.wait() for r in async_results]\n                ccgan.logger.warning('DONE! Starting new capture now.')\n            # Capture current model state, including metrics and visualizations\n            async_results = ccgan.gcapture(checkpoint=True, metrics=ccgan.step % metrics_step == 0, visualizations=True,\n                                           dataloader=dataloader, in_parallel=True, show_progress=True,\n                                           delete_after=True)\n        # Visualization code\n        elif ccgan.step % display_step == 0:\n            visualization_img = ccgan.visualize()\n            visualization_img.show() if not in_notebook() else display(visualization_img)\n\n        # Check if a pending checkpoint upload has finished\n        if async_results:\n            gcapture_ready = all([r.ready() for r in async_results])\n            if gcapture_ready:\n                ccgan.logger.info(f'gcapture() finished')\n                if ccgan.latest_checkpoint_had_metrics:\n                    ccgan.logger.info(str(ccgan.latest_metrics))\n                async_results = None\n\n        # If run locally one pass is enough\n        if run_locally and gcapture_ready:\n            break\n\n    # If run locally one pass is enough\n    if run_locally:\n        break\n\n    # noinspection PyProtectedMember\n    d = {\n        'step': ccgan.step,\n        'initial_step': ccgan.initial_step,\n        'epoch': ccgan.epoch,\n        '_counter': ccgan._counter,\n        'epoch_inc': ccgan.epoch_inc,\n    }\n    ccgan.logger.debug('[END OF EPOCH] ' + str(d))\n\n# Check if a pending checkpoint exists\nif async_results:\n    ([r.wait() for r in async_results])\n    ccgan.logger.info(f'last gcapture() finished')\n    if ccgan.latest_checkpoint_had_metrics:\n        ccgan.logger.info(str(ccgan.latest_metrics))\n    async_results = None\n\n# Training finished!\nccgan.logger.info('[training loop] DONE')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3) Evaluate CycleGAN\nIn this section we evaluate the generation performance of our trained network using the SOTA GAN evaluation metrics.\n\n## 3.1) Get the metrics evolution plots\nWe plot how the metrics evolved during training. The GAN is **not** trained to minimize those metrics (they are\ncalculated using `torch.no_grad()`) and thus this evolution merely depends on the network and showcases the  correlation between the GAN evaluation metrics, and the losses (e.g. adversarial & reconstruction) used to optimize the network.","metadata":{}},{"cell_type":"code","source":"# Since the CycleGAN implements utils.ifaces.Visualizable, we can\n# directly call visualize_metrics() on the model instance.\n_ = ccgan.visualize_metrics(upload=True, preview=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.2) Evaluate Generated Samples\nIn order to evaluate generated samples and compare model with other GAN architectures trained on the same dataset.\nFor this purpose we will re-calculate the evaluation metrics as stated above, but with a much bigger number of samples. In this way, the metrics will be more trustworthy and comparable with the corresponding metrics in the original paper.","metadata":{}},{"cell_type":"code","source":"# Initialize a new evaluator instance\n# (used to run GAN evaluation metrics: FID, IS, PRECISION, RECALL, F1 and SSIM)\nevaluator = GanEvaluator(model_fs_folder_or_root=models_groot, gen_dataset=dataloader.test_set, target_index=1,\n                         condition_indices=(0,), n_samples=10000, batch_size=128,\n                         device=exec_device, f1_k=f1_k, ssim_c_img=target_channels)\n\n# Run the evaluator\nmetrics_dict = evaluator.evaluate(gen=ccgan.gen, metric_name='all', show_progress=True)\n\n# Print results\nimport json\n\nprint(json.dumps(metrics_dict, indent=4))","metadata":{},"execution_count":null,"outputs":[]}]}