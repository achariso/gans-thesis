{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1) Set paths, check data, clone repo, install packages"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.1) Define paths\n",
    "These should be defined after successful upload of dataset and assets (e.g. git keys)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define dataset paths\n",
    "df_icrb_root = '/kaggle/input/deepfashion-icrb'\n",
    "df_icrb_img_root = f'{df_icrb_root}/Img'\n",
    "assert os.path.exists(df_icrb_img_root), f'df_icrb_img_root={df_icrb_img_root}: NOT FOUND'\n",
    "\n",
    "# Define asset paths\n",
    "git_keys_root = '/kaggle/input/git-keys/github-keys'\n",
    "assert os.path.exists(git_keys_root), f'git_keys_root={git_keys_root}: NOT FOUND'\n",
    "client_secrets_path = '/kaggle/input/git-keys/client_secrets.json'\n",
    "assert os.path.exists(client_secrets_path), f'client_secrets_path={client_secrets_path}: NOT FOUND'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create the root Google Drive directory. This is where all model checkpoints/metrics exists as well as Datasets, Fonts etc. Symlink to dataset Img folder to avoid code changes and enable interoperability with Google Colab"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create root directory if not exists\n",
    "gdrive_root = '/kaggle/working/GoogleDrive'\n",
    "!mkdir -p \"$gdrive_root\"\n",
    "\n",
    "# Create the Dataset link inside Google Drive\n",
    "gdrive_icrb_root = f'{gdrive_root}/Datasets/DeepFashion/In-shop Clothes Retrieval Benchmark'\n",
    "!mkdir -p \"$gdrive_root\"/Datasets/DeepFashion/In-shop\\ Clothes\\ Retrieval\\ Benchmark\n",
    "!ln -s /kaggle/input/deepfashion-icrb/Img \"$gdrive_icrb_root\"\n",
    "\n",
    "# Copy the Fonts dir inside local Google Drive root\n",
    "!cp -r /kaggle/input/mplfonts/Fonts \"$gdrive_root\"\n",
    "\n",
    "# Link the Inceptionv3 model Checkpoint inside local Google Drive root\n",
    "!mkdir -p \"$gdrive_root\"/Models\n",
    "!cp -r \"/kaggle/input/inception-model/model_name=inceptionv3\" \"$gdrive_root\"/Models\n",
    "!mv \"$gdrive_root\"/Models/model_name=inceptionv3/Checkpoints/1a9a5a14.pth.bak \"$gdrive_root\"/Models/model_name=inceptionv3/Checkpoints/1a9a5a14.pth\n",
    "\n",
    "# Create also an empty Img.zip file to fool GDriveDataset instance into thinking the dataset was downloaded\n",
    "# and unzipped\n",
    "!touch \"$gdrive_icrb_root\"/Img.zip\n",
    "\n",
    "# FIX: We need client_secrets.json to be writable, so copy to /kaggle/working\n",
    "!cp \"$client_secrets_path\" \"$gdrive_root\"\n",
    "client_secrets_path = f'{gdrive_root}/client_secrets.json'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2) Clone github repo\n",
    "Clone achariso/gans-thesis repo into /kaggle/working/code using git clone. For a similar procedure in Colab,\n",
    "see: https://medium.com/@purba0101/how-to-clone-private-github-repo-in-google-colab-using-ssh-77384cfef18f"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Clean failed attempts\n",
    "!rm -rf /root/.ssh\n",
    "!rm -rf /kaggle/working/code\n",
    "!mkdir -p /kaggle/working/code\n",
    "\n",
    "repo_root = '/kaggle/working/code/gans-thesis'\n",
    "if not os.path.exists(repo_root):\n",
    "    # Check that ssh keys exist\n",
    "    id_rsa_abs_drive = f'{git_keys_root}/id_rsa'\n",
    "    id_rsa_pub_abs_drive = f'{id_rsa_abs_drive}.pub'\n",
    "    assert os.path.exists(id_rsa_abs_drive)\n",
    "    assert os.path.exists(id_rsa_pub_abs_drive)\n",
    "    # On first run: Add ssh key in repo\n",
    "    if not os.path.exists('/root/.ssh'):\n",
    "        # Transfer config file\n",
    "        ssh_config_abs_drive = f'{git_keys_root}/config'\n",
    "        assert os.path.exists(ssh_config_abs_drive)\n",
    "        !mkdir -p ~/.ssh\n",
    "        !cp -f \"$ssh_config_abs_drive\" ~/.ssh/\n",
    "        # Add github.com to known hosts\n",
    "        !ssh-keyscan -t rsa github.com >> ~/.ssh/known_hosts\n",
    "        # Test ssh connection\n",
    "        # !ssh -T git@github.com\n",
    "\n",
    "    # Remove any previous attempts\n",
    "    !rm -rf \"$repo_root\"\n",
    "    !mkdir -p \"$repo_root\"\n",
    "    # Clone repo\n",
    "    !git clone git@github.com:achariso/gans-thesis.git \"$repo_root\"\n",
    "    src_root = f'{repo_root}/src'\n",
    "    !rm -rf \"$repo_root\"/report"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.3) Install pip packages\n",
    "All required files are stored in a requirements.txt files at the repository's root.\n",
    "Use `pip install -r requirements.txt` from inside the dir to install required packages."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%cd $repo_root\n",
    "!pip install -r requirements.txt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.4) Update path to include src dir\n",
    "This is necessary for the modules to function correctly"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "content_root_abs = f'{repo_root}'\n",
    "src_root_abs = f'{repo_root}/src'\n",
    "%env PYTHONPATH=\"/kaggle/lib/kagglegym:/kaggle/lib:$content_root_abs:$src_root_abs\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2) Train PGPG model on DeepFashion\n",
    "In this section we run the actual training loop for PGPG network. PGPG consists of a 2-stage generator, where each stage is a UNET-like model, and, in our version, a PatchGAN discriminator.\n",
    "\n",
    "\n",
    "### Colab Bug Workaround\n",
    "Bug: matplotlib cache not rebuilding.\n",
    "Solution: Run the following code and then restart the kernel (now included inside `src/train_pgpg.py`)\n",
    "\n",
    "\n",
    "### Actual Run\n",
    "Eventually, run the code!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "chkpt_step = None       # supported: 'latest', <int>, None\n",
    "log_level = 'debug'     # supported: 'debug', 'info', 'warning', 'error', 'critical', 'fatal'\n",
    "\n",
    "# Running with -i enables us to get variables defined inside the script (the script runs inline)\n",
    "%run -i src/train_pgpg.py"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3) Evaluate PGPG\n",
    "In this section we evaluate the generation performance of our trained network using the SOTA GAN evaluation metrics."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.1) Get the metrics evolution plots\n",
    "We plot how the metrics evolved during training. The GAN is **not** trained to minimize those metrics (they are\n",
    "calculated using `torch.no_grad()`) and thus this evolution merely depends on the network and showcases the correlation\n",
    "between the GAN evaluation metrics, and the losses (e.g. adversarial & reconstruction) used to optimize the network."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Since the PGPG implements utils.ifaces.Visualizable, we can\n",
    "# directly call visualize_metrics() on the model instance.\n",
    "_ = pgpg.visualize_metrics(upload=True, preview=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.2) Evaluate Generated Samples\n",
    "In order to evaluate generated samples and compare model with other GAN architectures trained on the same dataset. For this purpose we will re-calculate the evaluation metrics as stated above, but with a much bigger number of samples. In this way, the metrics will be more trustworthy and comparable with the corresponding metrics in the original paper.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Initialize a new evaluator instance\n",
    "# (used to run GAN evaluation metrics: FID, IS, PRECISION, RECALL, F1 and SSIM)\n",
    "evaluator = GanEvaluator(model_fs_folder_or_root=models_groot, gen_dataset=dataset, target_index=1, device=exec_device,\n",
    "                         condition_indices=(0, 2), n_samples=10000, batch_size=metrics_batch_size,\n",
    "                         f1_k=f1_k)\n",
    "# Run the evaluator\n",
    "metrics_dict = evaluator.evaluate(gen=pgpg.gen, metric_name='all', show_progress=True)\n",
    "\n",
    "# Print results\n",
    "import json\n",
    "print(json.dumps(metrics_dict, indent=4))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}