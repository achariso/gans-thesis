{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1) Mount drive, unzip data, clone repo, install packages"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.1) Mount Drive and define paths\n",
    "Run provided colab code to mount Google Drive. Then define dataset paths relative to mount point."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!rm -rf /content/sample_data\n",
    "!rm -rf /content/*.jpg\n",
    "!rm -rf /content/*.png\n",
    "!rm -rf /content/*.json"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# noinspection PyUnresolvedReferences,PyPackageRequirements\n",
    "from google.colab import drive\n",
    "mount_root_abs = '/content/drive'\n",
    "drive.mount(mount_root_abs)\n",
    "drive_root = f'{mount_root_abs}/MyDrive'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "# DeepFashion In-shop Clothes Retrieval Benchmark (ICRB)\n",
    "df_root_drive = f'{drive_root}/Datasets/DeepFashion'\n",
    "assert os.path.exists(df_root_drive)\n",
    "df_icrb_root_drive = f'{df_root_drive}/In-shop Clothes Retrieval Benchmark'\n",
    "assert os.path.exists(df_icrb_root_drive)\n",
    "df_icrb_img_zip_abs_drive = f'{df_icrb_root_drive}/Img.zip'\n",
    "\n",
    "# If Img.zip is not present, we need to unzip .../Img/img_iuv.zip directory\n",
    "# from drive root and then run ICRBScraper.run() from /src/dataset/deep_fashion.\n",
    "# For this nb, we skip this since it'll take an eternity to complete with\n",
    "# mounted Google Drive.\n",
    "assert os.path.exists(df_icrb_img_zip_abs_drive), \\\n",
    "  'Please upload a processed zip (processing img.zip in colab will take' + \\\n",
    "  f' for AGES). \\nTried: {df_icrb_img_zip_abs_drive}'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2) Unzip Img directory in Colab\n",
    "By unzipping the `Img.zip` in Colab before running our model we gain significant disk reading speedups.\n",
    "So, the first step is to unzip images directory, and then save the image directory before proceeding."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_icrb_root = df_icrb_root_drive.replace(drive_root, '/content/data')\n",
    "df_icrb_img_root = f'{df_icrb_root}/Img'\n",
    "if not os.path.exists(df_icrb_img_root):\n",
    "    # Clear any previous attempts\n",
    "    # ATTENTION: This will remove /contents/data/*. So, before running, please make\n",
    "    # sure no usable files will be deleted.\n",
    "    !mkdir -p /content/data\n",
    "    !rm -rf /content/data\n",
    "\n",
    "    # Create output directory\n",
    "    !mkdir -p \"$df_icrb_root\"\n",
    "\n",
    "    # Transfer Img.zip from Google Drive to Colab\n",
    "    df_icrb_img_zip_abs = f'{df_icrb_root}/{os.path.basename(df_icrb_img_zip_abs_drive)}'\n",
    "    if not os.path.exists(df_icrb_img_zip_abs):\n",
    "        !cp \"$df_icrb_img_zip_abs_drive\" \"$df_icrb_root\"\n",
    "    # Unzip it in Colab\n",
    "    !unzip -q \"$df_icrb_img_zip_abs\" -d \"$df_icrb_root\"\n",
    "    # Handle newly-created image directory\n",
    "    assert os.path.exists(df_icrb_img_root), f'df_icrb_img_root: {df_icrb_img_root}'\n",
    "    assert not os.path.exists(f'{df_icrb_img_root}/Img')\n",
    "    assert not os.path.exists(f'{df_icrb_img_root}/img')\n",
    "    !rm -f \"$df_icrb_img_zip_abs\"\n",
    "    assert not os.path.exists(df_icrb_img_zip_abs)\n",
    "\n",
    "    # Create a symbolic link back to drive (we need this to fool GDriveDataset\n",
    "    # into thinking that it done the unzipping)\n",
    "    if os.path.exists(f'{df_icrb_root_drive}/Img'):\n",
    "        !rm \"$df_icrb_root_drive\"/Img\n",
    "    !ln -s \"$df_icrb_img_root\" \"$df_icrb_root_drive\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.3) Clone github repo\n",
    "Clone achariso/gans-thesis repo into /content/code\n",
    " using git clone.\n",
    " For more info see: https://medium.com/@purba0101/how-to-clone-private-github-repo-in-google-colab-using-ssh-77384cfef18f"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "repo_root = '/content/code/gans-thesis'\n",
    "!rm -rf \"$repo_root\"\n",
    "if not os.path.exists(repo_root) and not os.path.exists(f'{repo_root}/requirements.txt'):\n",
    "    # Check that ssh keys exist\n",
    "    assert os.path.exists(f'{drive_root}/GitHub Keys')\n",
    "    id_rsa_abs_drive = f'{drive_root}/GitHub Keys/id_rsa'\n",
    "    id_rsa_pub_abs_drive = f'{id_rsa_abs_drive}.pub'\n",
    "    assert os.path.exists(id_rsa_abs_drive)\n",
    "    assert os.path.exists(id_rsa_pub_abs_drive)\n",
    "    # On first run: Add ssh key in repo\n",
    "    if not os.path.exists('/root/.ssh'):\n",
    "        # Transfer config file\n",
    "        ssh_config_abs_drive = f'{drive_root}/GitHub Keys/config'\n",
    "        assert os.path.exists(ssh_config_abs_drive)\n",
    "        !mkdir -p ~/.ssh\n",
    "        !cp -f \"$ssh_config_abs_drive\" ~/.ssh/\n",
    "        # # Add github.com to known hosts\n",
    "        !ssh-keyscan -t rsa github.com >> ~/.ssh/known_hosts\n",
    "        # Test: !ssh -T git@github.com\n",
    "\n",
    "    # Remove any previous attempts\n",
    "    !rm -rf \"$repo_root\"\n",
    "    !mkdir -p \"$repo_root\"\n",
    "    # Clone repo\n",
    "    !git clone git@github.com:achariso/gans-thesis.git \"$repo_root\"\n",
    "    src_root = f'{repo_root}/src'\n",
    "    !rm -rf \"$repo_root\"/report"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.4) Install pip packages\n",
    "All required files are stored in a requirements.txt files at the repository's root.\n",
    "Use `pip install -r requirements.txt` from inside the dir to install required packages."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%cd \"$repo_root\"\n",
    "!pip install -r requirements.txt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "assert torch.cuda.is_available()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.5) Add code/, */src/ to path\n",
    "This is necessary in order to be able to run the modules."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "content_root_abs = f'{repo_root}'\n",
    "src_root_abs = f'{repo_root}/src'\n",
    "%env PYTHONPATH=\"/env/python:$content_root_abs:$src_root_abs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2) Train PGPG model on DeepFashion\n",
    "In this section we run the actual training loop for PGPG network. PGPG consists of a 2-stage generator, where each stage is a UNET-like model, and, in our version, a PatchGAN discriminator."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Colab Bug Workaround\n",
    "Bug: matplotlib cache not rebuilding.\n",
    "Solution: Run the following code and then restart the kernel.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# now inside train_pgpg.py"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Actual Run\n",
    "Eventually, run the code!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "chkpt_step = 'latest'   # supported: 'latest', <int>, None\n",
    "log_level = 'debug'     # supported: 'debug', 'info', 'warning', 'error', 'critical', 'fatal'\n",
    "\n",
    "# From epoch=37, lambda_recon in G2's loss went from 1 --> 5\n",
    "# From epoch=66, lambda_recon in G2's loss went from 5 --> 10\n",
    "\n",
    "# Running with -i enables us to get variables defined inside the script (the script runs inline)\n",
    "%run -i src/train_setup.py\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### PGPG Training\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%cd src/\n",
    "\n",
    "from IPython.core.display import display\n",
    "from torch import Tensor\n",
    "# noinspection PyProtectedMember\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from datasets.deep_fashion import ICRBDataset, ICRBCrossPoseDataloader\n",
    "from modules.pgpg import PGPG\n",
    "from train_setup import run_locally, exec_device, log_level, datasets_groot, models_groot\n",
    "from utils.dep_free import get_tqdm, in_notebook\n",
    "from utils.ifaces import FilesystemDataset\n",
    "from utils.metrics import GanEvaluator\n",
    "\n",
    "###################################\n",
    "###  Hyper-parameters settings  ###\n",
    "###################################\n",
    "#   - training\n",
    "n_epochs = 100\n",
    "batch_size = 48 if not run_locally else 48\n",
    "train_test_splits = [90, 10]  # for a 90% training - 10% evaluation set split\n",
    "#   - evaluation\n",
    "metrics_n_samples = 1000 if not run_locally else 2\n",
    "metrics_batch_size = 32 if not run_locally else 1\n",
    "f1_k = 3 if not run_locally else 1\n",
    "#   - visualizations / checkpoints steps\n",
    "display_step = 200\n",
    "checkpoint_step = 600\n",
    "metrics_step = 1800  # evaluate model every 3 checkpoints\n",
    "#   - dataset\n",
    "target_shape = 128\n",
    "target_channels = 3\n",
    "skip_pose_norm = True\n",
    "#   - PGPG config file\n",
    "pgpg_config_id = f'{target_shape}_MSE_256_6_4_5_none_none_1e4_true_false_false'  # as proposed in the original paper\n",
    "\n",
    "###################################\n",
    "###   Dataset Initialization    ###\n",
    "###################################\n",
    "#   - image transforms:\n",
    "#     If target_shape is different from load one, resize & crop. If target_shape is different from load shape,\n",
    "#     convert to grayscale.\n",
    "#     Update: Now done automatically if you set target_channels, target_shape when instantiating the dataloader.\n",
    "gen_transforms = ICRBDataset.get_image_transforms(target_shape=target_shape, target_channels=target_channels)\n",
    "#   - the dataloader used to access the training dataset of cross-scale/pose image pairs at every epoch\n",
    "#     > len(dataloader) = <number of batches>\n",
    "#     > len(dataloader.dataset) = <number of total dataset items>\n",
    "dataloader = ICRBCrossPoseDataloader(dataset_fs_folder_or_root=datasets_groot, batch_size=batch_size,\n",
    "                                     image_transforms=gen_transforms, skip_pose_norm=skip_pose_norm,\n",
    "                                     splits=train_test_splits, pin_memory=not run_locally, log_level=log_level)\n",
    "dataset = dataloader.dataset\n",
    "#   - ensure dataset is fetched locally and unzipped\n",
    "if isinstance(dataset, FilesystemDataset):\n",
    "    dataset.fetch_and_unzip(in_parallel=False, show_progress=True)\n",
    "elif hasattr(dataset, 'dataset') and isinstance(dataset.dataset, FilesystemDataset):\n",
    "    dataset.dataset.fetch_and_unzip(in_parallel=False, show_progress=True)\n",
    "else:\n",
    "    raise TypeError('dataset must implement utils.ifaces.FilesystemDataset in order to be auto-downloaded and unzipped')\n",
    "#   - apply rudimentary tests\n",
    "assert issubclass(dataloader.__class__, DataLoader)\n",
    "assert len(dataloader) == len(dataset) // batch_size + (1 if len(dataset) % batch_size else 0)\n",
    "_image_1, _image_2, _dense_pose_2 = next(iter(dataloader))\n",
    "assert tuple(_image_1.shape) == (batch_size, target_channels, target_shape, target_shape)\n",
    "assert tuple(_image_2.shape) == (batch_size, target_channels, target_shape, target_shape)\n",
    "assert tuple(_dense_pose_2.shape) == (batch_size, target_channels, target_shape, target_shape)\n",
    "\n",
    "###################################\n",
    "###    Models Initialization    ###\n",
    "###################################\n",
    "#   - initialize evaluator instance (used to run GAN evaluation metrics: FID, IS, PRECISION, RECALL, F1 and SSIM)\n",
    "evaluator = GanEvaluator(model_fs_folder_or_root=models_groot, gen_dataset=dataset, target_index=1, device=exec_device,\n",
    "                         condition_indices=(0, 2), n_samples=metrics_n_samples, batch_size=metrics_batch_size,\n",
    "                         f1_k=f1_k)\n",
    "#   - initialize model\n",
    "global chkpt_step\n",
    "try:\n",
    "    if chkpt_step == 'latest':\n",
    "        pgpg_chkpt_step = chkpt_step\n",
    "    elif isinstance(chkpt_step, str) and chkpt_step.isdigit():\n",
    "        pgpg_chkpt_step = int(chkpt_step)\n",
    "    else:\n",
    "        pgpg_chkpt_step = None\n",
    "except NameError:\n",
    "    pgpg_chkpt_step = None\n",
    "pgpg = PGPG(model_fs_folder_or_root=models_groot, config_id=pgpg_config_id, dataset_len=len(dataset),\n",
    "            chkpt_epoch=pgpg_chkpt_step, evaluator=evaluator, device=exec_device, log_level=log_level)\n",
    "pgpg.logger.debug(f'Using device: {str(exec_device)}')\n",
    "pgpg.logger.debug(f'Model initialized. Number of params = {pgpg.nparams_hr}')\n",
    "#   - load dataloader state (from model checkpoint)\n",
    "if 'dataloader' in pgpg.other_state_dicts.keys():\n",
    "    dataloader.set_state(pgpg.other_state_dicts['dataloader'])\n",
    "    pgpg.logger.debug(f'Loaded dataloader state! Current pem_index={dataloader.get_state()[\"perm_index\"]}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### PGPG Main training loop\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import click\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "###################################\n",
    "###       Training Loop         ###\n",
    "###################################\n",
    "#   - get the correct tqdm instance\n",
    "exec_tqdm = get_tqdm()\n",
    "#   - start training loop from last checkpoint's epoch and step\n",
    "gcapture_ready = True\n",
    "async_results = None\n",
    "pgpg.logger.info(f'[training loop] STARTING (epoch={pgpg.epoch}, step={pgpg.initial_step})')\n",
    "for epoch in range(pgpg.epoch, n_epochs):\n",
    "    image_1: Tensor\n",
    "    image_2: Tensor\n",
    "    pose_2: Tensor\n",
    "\n",
    "    pgpg.logger.debug('[START OF EPOCH]')\n",
    "    d = {\n",
    "        'step': pgpg.step,\n",
    "        'initial_step': pgpg.initial_step,\n",
    "        'epoch': pgpg.epoch,\n",
    "        '_counter': pgpg._counter,\n",
    "        'epoch_inc': pgpg.epoch_inc,\n",
    "    }\n",
    "    pgpg.logger.debug(str(d))\n",
    "\n",
    "    initial_step = (pgpg.initial_step) % len(dataloader)\n",
    "    pgpg.logger.debug(f'[DATALODER] Initial Step = {initial_step}')\n",
    "    for image_1, image_2, pose_2 in get_tqdm()(dataloader, initial=initial_step):\n",
    "\n",
    "        # Transfer image batches to GPU\n",
    "        image_1 = image_1.to(exec_device)\n",
    "        image_2 = image_2.to(exec_device)\n",
    "        pose_2 = pose_2.to(exec_device)\n",
    "\n",
    "        pgpg.gforward(image_1.shape[0])\n",
    "        continue\n",
    "\n",
    "        # Perform a forward + backward pass + weight update on the Generator & Discriminator models\n",
    "        pgpg(image_1=image_1, image_2=image_2, pose_2=pose_2)\n",
    "\n",
    "        # Metrics & Checkpoint Code\n",
    "        if pgpg.step % checkpoint_step == 0:\n",
    "            # Check if another upload is pending\n",
    "            if not gcapture_ready and async_results:\n",
    "                # Wait for previous upload to finish\n",
    "                pgpg.logger.warning('Waiting for previous gcapture() to finish...')\n",
    "                [r.wait() for r in async_results]\n",
    "                pgpg.logger.warning('DONE! Starting new capture now.')\n",
    "            # Capture current model state, including metrics and visualizations\n",
    "            async_results = pgpg.gcapture(checkpoint=True, metrics=pgpg.step % metrics_step == 0, visualizations=True,\n",
    "                                          dataloader=dataloader, in_parallel=True, show_progress=True,\n",
    "                                          delete_after=False)\n",
    "        # Visualization code\n",
    "        elif pgpg.step % display_step == 0:\n",
    "            visualization_img = pgpg.visualize()\n",
    "            visualization_img.show() if not in_notebook() else display(visualization_img)\n",
    "\n",
    "        # Check if a pending checkpoint upload has finished\n",
    "        if async_results:\n",
    "            gcapture_ready = all([r.ready() for r in async_results])\n",
    "            if gcapture_ready:\n",
    "                pgpg.logger.info(f'gcapture() finished')\n",
    "                if pgpg.latest_checkpoint_had_metrics:\n",
    "                    pgpg.logger.info(str(pgpg.latest_metrics))\n",
    "                async_results = None\n",
    "\n",
    "        # If run locally one pass is enough\n",
    "        if run_locally and gcapture_ready:\n",
    "            break\n",
    "\n",
    "    # If run locally one pass is enough\n",
    "    if run_locally:\n",
    "        break\n",
    "\n",
    "    pgpg.logger.debug('[END OF EPOCH]')\n",
    "    d = {\n",
    "        'step': pgpg.step,\n",
    "        'initial_step': pgpg.initial_step,\n",
    "        'epoch': pgpg.epoch,\n",
    "        '_counter': pgpg._counter,\n",
    "        'epoch_inc': pgpg.epoch_inc,\n",
    "    }\n",
    "    pgpg.logger.debug(str(d))\n",
    "    if not click.confirm(f'Run a new epoch?', default=True):\n",
    "      break\n",
    "\n",
    "# Check if a pending checkpoint exists\n",
    "if async_results:\n",
    "    ([r.wait() for r in async_results])\n",
    "    pgpg.logger.info(f'last gcapture() finished')\n",
    "    if pgpg.latest_checkpoint_had_metrics:\n",
    "        pgpg.logger.info(str(pgpg.latest_metrics))\n",
    "    async_results = None\n",
    "\n",
    "# Training finished!\n",
    "pgpg.logger.info('[training loop] DONE')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3) Evaluate PGPG\n",
    "In this section we evaluate the generation performance of our trained network using the SOTA GAN evaluation metrics."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.1) Get the metrics evolution plots\n",
    "We plot how the metrics evolved during training. The GAN is **not** trained to minimize those metrics (they are\n",
    "calculated using `torch.no_grad()`) and thus this evolution merely depends on the network and showcases the correlation\n",
    "between the GAN evaluation metrics, and the losses (e.g. adversarial & reconstruction) used to optimize the network."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Since the PGPG implements utils.ifaces.Visualizable, we can\n",
    "# directly call visualize_metrics() on the model instance.\n",
    "_ = pgpg.visualize_metrics(upload=True, preview=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.2) Evaluate Generated Samples\n",
    "In order to evaluate generated samples and compare model with other GAN architectures trained on the same dataset. For this purpose we will re-calculate the evaluation metrics as stated above, but with a much bigger number of samples. In this way, the metrics will be more trustworthy and comparable with the corresponding metrics in the original paper.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Initialize a new evaluator instance\n",
    "# (used to run GAN evaluation metrics: FID, IS, PRECISION, RECALL, F1 and SSIM)\n",
    "evaluator = GanEvaluator(model_fs_folder_or_root=models_groot, gen_dataset=dataset, target_index=1, device=exec_device,\n",
    "                         condition_indices=(0, 2), n_samples=10000, batch_size=metrics_batch_size,\n",
    "                         f1_k=f1_k)\n",
    "# Run the evaluator\n",
    "metrics_dict = evaluator.evaluate(gen=pgpg.gen, metric_name='all', show_progress=True)\n",
    "\n",
    "# Print results\n",
    "import json\n",
    "print(json.dumps(metrics_dict, indent=4))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}