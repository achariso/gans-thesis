{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "name": "pxldtg_debug.ipynb",
      "provenance": []
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0fbbb8718bb541febc99fbe3ed908b02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9fe55686eb24455885ba5f8cf9d2da01",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_01461baac0d04d5fa619c8089533c765",
              "IPY_MODEL_7aa5e6c0832043cbbc715001ae4e028b"
            ]
          }
        },
        "9fe55686eb24455885ba5f8cf9d2da01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "01461baac0d04d5fa619c8089533c765": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b3429904663b4cbeb8979200cbf2e3a5",
            "_dom_classes": [],
            "description": "  2%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1346,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 31,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_502542ac4c07487e83943c495584d108"
          }
        },
        "7aa5e6c0832043cbbc715001ae4e028b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4d095b10e2c94ce288951ff006c17b46",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 31/1346 [02:10&lt;1:31:58,  4.20s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_015fb3ad3d324153a28d2aeea671092e"
          }
        },
        "b3429904663b4cbeb8979200cbf2e3a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "502542ac4c07487e83943c495584d108": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4d095b10e2c94ce288951ff006c17b46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "015fb3ad3d324153a28d2aeea671092e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "gbPe-ZvX-NkH"
      },
      "source": [
        "# 1) Mount drive, unzip data, clone repo, install packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "1AeDFep2-NkR"
      },
      "source": [
        "## 1.1) Mount Drive and define paths\n",
        "Run provided colab code to mount Google Drive. Then define dataset paths relative to mount point."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "EvKC81RU-NkR"
      },
      "source": [
        "!rm -rf /content/sample_data\n",
        "!rm -rf /content/*.jpg\n",
        "!rm -rf /content/*.png\n",
        "!rm -rf /content/*.json"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5Z4kWQs-NkS",
        "outputId": "fe4fa568-4e4d-4533-9e65-2947db5d4487"
      },
      "source": [
        "# noinspection PyUnresolvedReferences,PyPackageRequirements\n",
        "from google.colab import drive\n",
        "mount_root_abs = '/content/drive'\n",
        "drive.mount(mount_root_abs)\n",
        "drive_root = f'{mount_root_abs}/MyDrive'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "LsbQGZcN-NkS"
      },
      "source": [
        "import os\n",
        "# LookBook + (partially) DeepFashion In-shop Clothes Retrieval Benchmark (ICRB)\n",
        "lb_root_drive = f'{drive_root}/Datasets/LookBook'\n",
        "assert os.path.exists(lb_root_drive)\n",
        "lb_img_zip_abs_drive = f'{lb_root_drive}/Img.zip'\n",
        "\n",
        "# Test if processed Img.zip file exists in dataset root\n",
        "assert os.path.exists(lb_img_zip_abs_drive), \\\n",
        "  'Please upload a processed zip (processing img.zip in colab will take' + \\\n",
        "  f' for AGES). \\nTried: {lb_img_zip_abs_drive}'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "aOubeDNU-NkS"
      },
      "source": [
        "## 1.2) Unzip Img directory in Colab\n",
        "By unzipping the `Img.zip` in Colab before running our model we gain significant disk reading speedups.\n",
        "So, the first step is to unzip images directory, and then save the image directory before proceeding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "FO5e9P9O-NkS"
      },
      "source": [
        "lb_root = lb_root_drive.replace(drive_root, '/content/data')\n",
        "lb_img_root = f'{lb_root}/Img'\n",
        "if not os.path.exists(lb_img_root):\n",
        "    # Clear any previous attempts\n",
        "    # ATTENTION: This will remove /contents/data/*. So, before running, please \n",
        "    # make sure no usable files will be deleted.\n",
        "    !mkdir -p /content/data\n",
        "    !rm -rf /content/data\n",
        "\n",
        "    # Create output directory\n",
        "    !mkdir -p \"$lb_root\"\n",
        "\n",
        "    # Transfer Img.zip from Google Drive to Colab\n",
        "    lb_img_zip_abs = f'{lb_root}/{os.path.basename(lb_img_zip_abs_drive)}'\n",
        "    if not os.path.exists(lb_img_zip_abs):\n",
        "        !cp \"$lb_img_zip_abs_drive\" \"$lb_root\"\n",
        "    # Unzip it in Colab\n",
        "    !unzip -q \"$lb_img_zip_abs\" -d \"$lb_root\"\n",
        "    # Handle newly-created image directory\n",
        "    assert os.path.exists(lb_img_root), f'lb_img_root: {lb_img_root}'\n",
        "    assert not os.path.exists(f'{lb_img_root}/Img')\n",
        "    !rm -f \"$lb_img_zip_abs\"\n",
        "    assert not os.path.exists(lb_img_zip_abs)\n",
        "\n",
        "    # Create a symbolic link back to drive (we need this to fool GDriveDataset\n",
        "    # into thinking that it done the unzipping)\n",
        "    if os.path.exists(f'{lb_root_drive}/Img'):\n",
        "        !rm \"$lb_root_drive\"/Img\n",
        "    !ln -s \"$lb_img_root\" \"$lb_root_drive\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "ntYgqTyp-NkT"
      },
      "source": [
        "## 1.3) Clone github repo\n",
        "Clone achariso/gans-thesis repo into /content/code\n",
        " using git clone.\n",
        " For more info see: https://medium.com/@purba0101/how-to-clone-private-github-repo-in-google-colab-using-ssh-77384cfef18f"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1lIuIOm-NkT",
        "outputId": "eece5ddc-2e80-445b-d578-5299df3fff91"
      },
      "source": [
        "repo_root = '/content/code/gans-thesis'\n",
        "!rm -rf \"$repo_root\"\n",
        "if not os.path.exists(repo_root) and not os.path.exists(f'{repo_root}/requirements.txt'):\n",
        "    # Check that ssh keys exist\n",
        "    assert os.path.exists(f'{drive_root}/GitHub Keys')\n",
        "    id_rsa_abs_drive = f'{drive_root}/GitHub Keys/id_rsa'\n",
        "    id_rsa_pub_abs_drive = f'{id_rsa_abs_drive}.pub'\n",
        "    assert os.path.exists(id_rsa_abs_drive)\n",
        "    assert os.path.exists(id_rsa_pub_abs_drive)\n",
        "    # On first run: Add ssh key in repo\n",
        "    if not os.path.exists('/root/.ssh'):\n",
        "        # Transfer config file\n",
        "        ssh_config_abs_drive = f'{drive_root}/GitHub Keys/config'\n",
        "        assert os.path.exists(ssh_config_abs_drive)\n",
        "        !mkdir -p ~/.ssh\n",
        "        !cp -f \"$ssh_config_abs_drive\" ~/.ssh/\n",
        "        # # Add github.com to known hosts\n",
        "        !ssh-keyscan -t rsa github.com >> ~/.ssh/known_hosts\n",
        "        # Test: !ssh -T git@github.com\n",
        "\n",
        "    # Remove any previous attempts\n",
        "    !rm -rf \"$repo_root\"\n",
        "    !mkdir -p \"$repo_root\"\n",
        "    # Clone repo\n",
        "    !git clone git@github.com:achariso/gans-thesis.git \"$repo_root\"\n",
        "    src_root = f'{repo_root}/src'\n",
        "    !rm -rf \"$repo_root\"/report"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into '/content/code/gans-thesis'...\n",
            "remote: Enumerating objects: 868, done.\u001b[K\n",
            "remote: Counting objects: 100% (868/868), done.\u001b[K\n",
            "remote: Compressing objects: 100% (598/598), done.\u001b[K\n",
            "remote: Total 1479 (delta 593), reused 526 (delta 260), pack-reused 611\u001b[K\n",
            "Receiving objects: 100% (1479/1479), 791.17 KiB | 1.31 MiB/s, done.\n",
            "Resolving deltas: 100% (948/948), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "Mt8BqZ75-NkU"
      },
      "source": [
        "## 1.4) Install pip packages\n",
        "All required files are stored in a requirements.txt files at the repository's root.\n",
        "Use `pip install -r requirements.txt` from inside the dir to install required packages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAc139SU-NkU",
        "outputId": "0e2c6adf-28a4-4de5-f89c-fc0dd879c17d"
      },
      "source": [
        "%cd \"$repo_root\"\n",
        "!pip install -r requirements.txt"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/code/gans-thesis\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (7.1.2)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (1.8.1+cu101)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (0.9.1+cu101)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (0.5.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (3.2.2)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (4.8.0)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (1.19.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (7.1.2)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 13)) (5.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 14)) (1.4.1)\n",
            "Requirement already satisfied: httplib2==0.15.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 15)) (0.15.0)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 16)) (4.1.3)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 17)) (1.12.8)\n",
            "Requirement already satisfied: pydrive in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 18)) (1.3.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 19)) (2.4.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 20)) (5.4.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7.0->-r requirements.txt (line 3)) (3.7.4.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 6)) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 6)) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 6)) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 6)) (2.4.7)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prettytable->-r requirements.txt (line 8)) (0.2.5)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from prettytable->-r requirements.txt (line 8)) (3.8.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->-r requirements.txt (line 9)) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->-r requirements.txt (line 9)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->-r requirements.txt (line 9)) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->-r requirements.txt (line 9)) (2.10)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 13)) (0.8.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 13)) (2.6.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 13)) (5.0.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 13)) (1.0.18)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 13)) (4.4.2)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 13)) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 13)) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 13)) (54.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from oauth2client->-r requirements.txt (line 16)) (0.2.8)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from oauth2client->-r requirements.txt (line 16)) (1.15.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client->-r requirements.txt (line 16)) (0.4.8)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from oauth2client->-r requirements.txt (line 16)) (4.7.2)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client->-r requirements.txt (line 17)) (1.26.2)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client->-r requirements.txt (line 17)) (3.0.1)\n",
            "Requirement already satisfied: google-auth>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client->-r requirements.txt (line 17)) (1.28.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client->-r requirements.txt (line 17)) (0.0.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 19)) (0.4.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 19)) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 19)) (1.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 19)) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 19)) (0.36.2)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 19)) (3.12.4)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 19)) (1.32.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 19)) (0.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->prettytable->-r requirements.txt (line 8)) (3.4.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->ipython->-r requirements.txt (line 13)) (0.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->-r requirements.txt (line 13)) (0.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client->-r requirements.txt (line 17)) (1.53.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client->-r requirements.txt (line 17)) (2018.9)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client->-r requirements.txt (line 17)) (20.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client->-r requirements.txt (line 17)) (4.2.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 19)) (1.3.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 19)) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "AQRIhKXs-NkU"
      },
      "source": [
        "import torch\n",
        "assert torch.cuda.is_available()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "EhZWMWMu-NkU"
      },
      "source": [
        "## 1.5) Add code/, */src/ to path\n",
        "This is necessary in order to be able to run the modules."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gq1Tph8v-NkU",
        "outputId": "2151b761-8245-4fc4-e131-fa570d7fa03b"
      },
      "source": [
        "content_root_abs = f'{repo_root}'\n",
        "src_root_abs = f'{repo_root}/src'\n",
        "%env PYTHONPATH=\"/env/python:$content_root_abs:$src_root_abs"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env: PYTHONPATH=\"/env/python:/content/code/gans-thesis:/content/code/gans-thesis/src\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "Uy6DRL0S-NkU"
      },
      "source": [
        "# 2) Train PixelDTGAN model on LookBook + DeepFashion (part of the ICRB dataset)\n",
        "In this section we run the actual training loop for PixelDTGan network. PixelDTGAN consists of a AE-like generator, and, in our version, two PatchGAN discriminators."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "8N0L9AAV-NkV"
      },
      "source": [
        "### Colab Bug Workaround\n",
        "Bug: matplotlib cache not rebuilding.\n",
        "Solution: Run the following code and then restart the kernel.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "aFgK5mX5-NkV"
      },
      "source": [
        "# now inside train_pxldtg.py"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "vLpuOKli-NkV"
      },
      "source": [
        "### Actual Run\n",
        "Eventually, run the code!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "q3v3ab5x-NkV"
      },
      "source": [
        "chkpt_step = None       # supported: 'latest', <int>, None\n",
        "log_level = 'debug'     # supported: 'debug', 'info', 'warning', 'error', 'critical', 'fatal'\n",
        "\n",
        "# From epoch=37, lambda_recon in G2's loss went from 1 --> 5\n",
        "# From epoch=66, lambda_recon in G2's loss went from 5 --> 10\n",
        "\n",
        "# Running with -i enables us to get variables defined inside the script (the script runs inline)\n",
        "%run -i src/train_setup.py --log_level $log_level --chkpt_step $chkpt_step --seed 42\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "cwqTPmw9-NkV"
      },
      "source": [
        "### PixelDTGAN Training\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfgy14_N-NkW",
        "outputId": "dfcaa448-1f87-4102-e125-5eff8da31f8d"
      },
      "source": [
        "%cd src/\n",
        "\n",
        "import torch\n",
        "from IPython.core.display import display\n",
        "from torch import Tensor\n",
        "from torch.nn import DataParallel\n",
        "# noinspection PyProtectedMember\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from datasets.look_book import PixelDTDataset, PixelDTDataloader\n",
        "from modules.pixel_dt_gan import PixelDTGan\n",
        "from utils.dep_free import get_tqdm\n",
        "from utils.ifaces import FilesystemDataset\n",
        "from utils.metrics import GanEvaluator\n",
        "\n",
        "###################################\n",
        "###  Hyper-parameters settings  ###\n",
        "###################################\n",
        "# TODO: finish this notebook and train in Colab/Kaggle\n",
        "#   - training\n",
        "n_epochs = 100\n",
        "batch_size = 48 if not run_locally else 48\n",
        "train_test_splits = [90, 10]  # for a 90% training - 10% evaluation set split\n",
        "#   - evaluation\n",
        "metrics_n_samples = 1000 if not run_locally else 2\n",
        "metrics_batch_size = 32 if not run_locally else 1\n",
        "f1_k = 3 if not run_locally else 1\n",
        "#   - visualizations / checkpoints steps\n",
        "display_step = 200\n",
        "checkpoint_step = 600\n",
        "metrics_step = 1800  # evaluate model every 3 checkpoints\n",
        "#   - dataset\n",
        "target_shape = 128\n",
        "target_channels = 3\n",
        "#   - PixelDTGAN configiguration\n",
        "pxldtg_config_id = f'default'  # as proposed in the original paper\n",
        "\n",
        "###################################\n",
        "###   Dataset Initialization    ###\n",
        "###################################\n",
        "#   - image transforms:\n",
        "#     If target_shape is different from load one, resize & crop. If target_shape is different from load shape,\n",
        "#     convert to grayscale.\n",
        "#     Update: Now done automatically if you set target_channels, target_shape when instantiating the dataloader.\n",
        "gen_transforms = PixelDTDataset.get_image_transforms(target_shape=PixelDTGan.DefaultConfiguration['shapes']['w_in'], target_channels=3)\n",
        "#   - the dataloader used to access the training dataset of cross-scale/pose image pairs at every epoch\n",
        "#     > len(dataloader) = <number of batches>\n",
        "#     > len(dataloader.dataset) = <number of total dataset items>\n",
        "dataloader = PixelDTDataloader(dataset_fs_folder_or_root=datasets_groot, batch_size=batch_size,\n",
        "                               image_transforms=gen_transforms, splits=train_test_splits,\n",
        "                               pin_memory=not run_locally, log_level=log_level)\n",
        "dataset = dataloader.dataset\n",
        "#   - ensure dataset is fetched locally and unzipped\n",
        "if isinstance(dataset, FilesystemDataset):\n",
        "    dataset.fetch_and_unzip(in_parallel=False, show_progress=True)\n",
        "elif hasattr(dataset, 'dataset') and isinstance(dataset.dataset, FilesystemDataset):\n",
        "    dataset.dataset.fetch_and_unzip(in_parallel=False, show_progress=True)\n",
        "else:\n",
        "    raise TypeError('dataset must implement utils.ifaces.FilesystemDataset in order to be auto-downloaded and unzipped')\n",
        "#   - apply rudimentary tests\n",
        "assert issubclass(dataloader.__class__, DataLoader)\n",
        "assert len(dataloader) == len(dataset) // batch_size + (1 if len(dataset) % batch_size else 0)\n",
        "_img_s, _img_t = next(iter(dataloader))\n",
        "assert tuple(_img_s.shape) == (batch_size, target_channels, target_shape, target_shape)\n",
        "assert tuple(_img_t.shape) == (batch_size, target_channels, target_shape, target_shape)\n",
        "\n",
        "###################################\n",
        "###    Models Initialization    ###\n",
        "###################################\n",
        "#   - initialize evaluator instance (used to run GAN evaluation metrics: FID, IS, PRECISION, RECALL, F1 and SSIM)\n",
        "evaluator = GanEvaluator(model_fs_folder_or_root=models_groot, gen_dataset=dataset, target_index=1, device=exec_device,\n",
        "                         condition_indices=(0, ), n_samples=metrics_n_samples, batch_size=metrics_batch_size,\n",
        "                         f1_k=f1_k)\n",
        "#   - initialize model\n",
        "chkpt_step = args.chkpt_step\n",
        "try:\n",
        "    if chkpt_step == 'latest':\n",
        "        pxldtg_chkpt_step = chkpt_step\n",
        "    elif isinstance(chkpt_step, str) and chkpt_step.isdigit():\n",
        "        pxldtg_chkpt_step = int(chkpt_step)\n",
        "    else:\n",
        "        pxldtg_chkpt_step = None\n",
        "except NameError:\n",
        "    pxldtg_chkpt_step = None\n",
        "pxldtg = PixelDTGan(model_fs_folder_or_root=models_groot, config_id=pxldtg_config_id, dataset_len=len(dataset),\n",
        "            chkpt_epoch=pxldtg_chkpt_step, evaluator=evaluator, device=exec_device, log_level=log_level)\n",
        "pxldtg.logger.debug(f'Using device: {str(exec_device)}')\n",
        "pxldtg.logger.debug(f'Model initialized. Number of params = {pxldtg.nparams_hr}')\n",
        "#   - setup multi-GPU training\n",
        "if torch.cuda.device_count() > 1:\n",
        "    pxldtg.gen = DataParallel(pxldtg.gen)\n",
        "    pxldtg.info(f'Using {torch.cuda.device_count()} GPUs for PixelDTGAN Generator (via torch.nn.DataParallel)')\n",
        "#   - load dataloader state (from model checkpoint)\n",
        "if 'dataloader' in pxldtg.other_state_dicts.keys():\n",
        "    dataloader.set_state(pxldtg.other_state_dicts['dataloader'])\n",
        "    pxldtg.logger.debug(f'Loaded dataloader state! Current pem_index={dataloader.get_state()[\"perm_index\"]}')\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/code/gans-thesis/src\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mFound 71.7K image pairs in dataset\u001b[0m\n",
            "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mSplit dataset: len(training_set)=64.6K, len(test_set)=7.2K\u001b[0m\n",
            "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mDataset is fetched and unzipped!\u001b[0m\n",
            "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mUsing device: cuda:0\u001b[0m\n",
            "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mModel initialized. Number of params = 59.9M\u001b[0m\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "Ghwkg85n-NkX"
      },
      "source": [
        "### PixelDTGAN Main training loop\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "0fbbb8718bb541febc99fbe3ed908b02",
            "9fe55686eb24455885ba5f8cf9d2da01",
            "01461baac0d04d5fa619c8089533c765",
            "7aa5e6c0832043cbbc715001ae4e028b",
            "b3429904663b4cbeb8979200cbf2e3a5",
            "502542ac4c07487e83943c495584d108",
            "4d095b10e2c94ce288951ff006c17b46",
            "015fb3ad3d324153a28d2aeea671092e"
          ]
        },
        "id": "RwWCR4-O-NkX",
        "outputId": "e4a648bb-e573-493b-b85b-d1335c6029fe"
      },
      "source": [
        "import click\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "###################################\n",
        "###       Training Loop         ###\n",
        "###################################\n",
        "#   - get the correct tqdm instance\n",
        "exec_tqdm = get_tqdm()\n",
        "#   - start training loop from last checkpoint's epoch and step\n",
        "gcapture_ready = True\n",
        "async_results = None\n",
        "pxldtg.logger.info(f'[training loop] STARTING (epoch={pxldtg.epoch}, step={pxldtg.initial_step})')\n",
        "for epoch in range(pxldtg.epoch, n_epochs):\n",
        "    image_1: Tensor\n",
        "    image_2: Tensor\n",
        "    pose_2: Tensor\n",
        "\n",
        "    # noinspection PyProtectedMember\n",
        "    d = {\n",
        "        'step': pxldtg.step,\n",
        "        'initial_step': pxldtg.initial_step,\n",
        "        'epoch': pxldtg.epoch,\n",
        "        '_counter': pxldtg._counter,\n",
        "        'epoch_inc': pxldtg.epoch_inc,\n",
        "    }\n",
        "    # initial_step = pxldtg.initial_step % len(dataloader)\n",
        "    pxldtg.logger.debug('[START OF EPOCH] ' + str(d))\n",
        "    for img_s, img_t in get_tqdm()(dataloader, initial=pxldtg.initial_step):\n",
        "        # Transfer image batches to GPU\n",
        "        img_s = img_s.to(exec_device)\n",
        "        img_t = img_t.to(exec_device)\n",
        "\n",
        "        # Perform a forward + backward pass + weight update on the Generator & Discriminator models\n",
        "        disc_r_loss, disc_a_loss, gen_loss = pxldtg(img_s, img_t)\n",
        "\n",
        "        # Metrics & Checkpoint Code\n",
        "        if pxldtg.step % checkpoint_step == 0:\n",
        "            # Check if another upload is pending\n",
        "            if not gcapture_ready and async_results:\n",
        "                # Wait for previous upload to finish\n",
        "                pxldtg.logger.warning('Waiting for previous gcapture() to finish...')\n",
        "                [r.wait() for r in async_results]\n",
        "                pxldtg.logger.warning('DONE! Starting new capture now.')\n",
        "            # Capture current model state, including metrics and visualizations\n",
        "            async_results = pxldtg.gcapture(checkpoint=True, metrics=pxldtg.step % metrics_step == 0, visualizations=True,\n",
        "                                          dataloader=dataloader, in_parallel=True, show_progress=True,\n",
        "                                          delete_after=False)\n",
        "        # Visualization code\n",
        "        elif pxldtg.step % display_step == 0:\n",
        "            visualization_img = pxldtg.visualize()\n",
        "            visualization_img.show() if not in_notebook() else display(visualization_img)\n",
        "\n",
        "        # Check if a pending checkpoint upload has finished\n",
        "        if async_results:\n",
        "            gcapture_ready = all([r.ready() for r in async_results])\n",
        "            if gcapture_ready:\n",
        "                pxldtg.logger.info(f'gcapture() finished')\n",
        "                if pxldtg.latest_checkpoint_had_metrics:\n",
        "                    pxldtg.logger.info(str(pxldtg.latest_metrics))\n",
        "                async_results = None\n",
        "\n",
        "        # If run locally one pass is enough\n",
        "        if run_locally and gcapture_ready:\n",
        "            break\n",
        "\n",
        "    # If run locally one pass is enough\n",
        "    if run_locally:\n",
        "        break\n",
        "\n",
        "    # noinspection PyProtectedMember\n",
        "    d = {\n",
        "        'step': pxldtg.step,\n",
        "        'initial_step': pxldtg.initial_step,\n",
        "        'epoch': pxldtg.epoch,\n",
        "        '_counter': pxldtg._counter,\n",
        "        'epoch_inc': pxldtg.epoch_inc,\n",
        "    }\n",
        "    pxldtg.logger.debug('[END OF EPOCH] ' + str(d))\n",
        "\n",
        "# Check if a pending checkpoint exists\n",
        "if async_results:\n",
        "    ([r.wait() for r in async_results])\n",
        "    pxldtg.logger.info(f'last gcapture() finished')\n",
        "    if pxldtg.latest_checkpoint_had_metrics:\n",
        "        pxldtg.logger.info(str(pxldtg.latest_metrics))\n",
        "    async_results = None\n",
        "\n",
        "# Training finished!\n",
        "pxldtg.logger.info('[training loop] DONE')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  \u001b[32mINFO    \u001b[0m | \u001b[32m[training loop] STARTING (epoch=0, step=0)\u001b[0m\n",
            "  \u001b[37mDEBUG   \u001b[0m | \u001b[37m[START OF EPOCH] {'step': None, 'initial_step': 0, 'epoch': 0, '_counter': 0, 'epoch_inc': False}\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0fbbb8718bb541febc99fbe3ed908b02",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1346.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "_IBJPgDI-NkY"
      },
      "source": [
        "# 3) Evaluate PixelDTGAN\n",
        "In this section we evaluate the generation performance of our trained network using the SOTA GAN evaluation metrics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "TwtVO9vH-NkY"
      },
      "source": [
        "## 3.1) Get the metrics evolution plots\n",
        "We plot how the metrics evolved during training. The GAN is **not** trained to minimize those metrics (they are\n",
        "calculated using `torch.no_grad()`) and thus this evolution merely depends on the network and showcases the correlation\n",
        "between the GAN evaluation metrics, and the losses (e.g. adversarial & reconstruction) used to optimize the network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "rpNgcsLr-NkY"
      },
      "source": [
        "# Since the PixelDTGAN implements utils.ifaces.Visualizable, we can\n",
        "# directly call visualize_metrics() on the model instance.\n",
        "_ = pxldtg.visualize_metrics(upload=True, preview=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "SsYiy5gP-NkY"
      },
      "source": [
        "## 3.2) Evaluate Generated Samples\n",
        "In order to evaluate generated samples and compare model with other GAN architectures trained on the same dataset. For this purpose we will re-calculate the evaluation metrics as stated above, but with a much bigger number of samples. In this way, the metrics will be more trustworthy and comparable with the corresponding metrics in the original paper.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "wqL_pDkc-NkZ"
      },
      "source": [
        "# Initialize a new evaluator instance\n",
        "# (used to run GAN evaluation metrics: FID, IS, PRECISION, RECALL, F1 and SSIM)\n",
        "evaluator = GanEvaluator(model_fs_folder_or_root=models_groot, gen_dataset=dataset, target_index=1, device=exec_device,\n",
        "                         condition_indices=(0, 2), n_samples=10000, batch_size=metrics_batch_size,\n",
        "                         f1_k=f1_k, ssim_c_img=target_channels)\n",
        "# Run the evaluator\n",
        "metrics_dict = evaluator.evaluate(gen=pxldtg.gen, metric_name='all', show_progress=True)\n",
        "\n",
        "# Print results\n",
        "import json\n",
        "print(json.dumps(metrics_dict, indent=4))\n",
        "\n",
        "#-----------\n",
        "# Epoch 93\n",
        "#----------\n",
        "# {\n",
        "#   \"fid\": 16.195581436157227\n",
        "#   \"is\": 2.82967472076416\n",
        "#   \"f1\": 0.8827780485153198\n",
        "#   \"precision\": 0.8856828808784485\n",
        "#   \"recall\": 0.8798921704292297\n",
        "#   \"ssim\": 0.8029271364212036\n",
        "# }"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}