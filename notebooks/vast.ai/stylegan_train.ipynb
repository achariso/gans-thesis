{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5df76d13",
   "metadata": {},
   "source": [
    "# 1) Mount drive, unzip data, clone repo, install packages\n",
    "\n",
    "## 1.1) Define paths\n",
    "Main Google Drive root: `/workspace/GoogleDrive`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a89b47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from ipywidgets import FileUpload\n",
    "\n",
    "# Define Google Drive related paths\n",
    "drive_root = \"/workspace/GoogleDrive\"\n",
    "!mkdir -p \"$drive_root\"\n",
    "!mkdir -p \"$drive_root/Models\"\n",
    "!mkdir -p \"$drive_root/Datasets\"\n",
    "!mkdir -p \"$drive_root/GitHub Keys\"\n",
    "\n",
    "# Upload ssh keys\n",
    "is_first_run = not os.path.exists(f'{drive_root}/GitHub Keys/config') or not os.path.exists(f'{drive_root}/GitHub Keys/id_rsa') or not os.path.exists(f'{drive_root}/client_secrets.json')\n",
    "if is_first_run:\n",
    "    #   - config\n",
    "    with open(f'{drive_root}/GitHub Keys/config', 'w') as fp:\n",
    "        fp.writelines(['Host github.com\\n', '    Hostname github.com\\n', f'    IdentityFile \"{drive_root}/GitHub Keys/id_rsa\"\\n', '    IdentitiesOnly yes\\n'])\n",
    "    #   - id_rsa.pub\n",
    "    upload = FileUpload(multiple=True)\n",
    "    display(upload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7d0f3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_first_run:\n",
    "    with open(f'{drive_root}/GitHub Keys/id_rsa', 'w+b') as i:\n",
    "        i.write(upload.value['id_rsa']['content'])\n",
    "    !chmod 600 \"$drive_root/GitHub Keys/id_rsa\"\n",
    "    with open(f'{drive_root}/GitHub Keys/id_rsa.pub', 'w+b') as i:\n",
    "        i.write(upload.value['id_rsa.pub']['content'])\n",
    "    !chmod 600 \"$drive_root/GitHub Keys/id_rsa.pub\"\n",
    "\n",
    "    # client_secrets.json\n",
    "    with open(f'{drive_root}/client_secrets.json', 'w+b') as i:\n",
    "        i.write(upload.value['client_secrets.json']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03840efa",
   "metadata": {},
   "source": [
    "## 1.2) Clone GitHub repo\n",
    "Clone achariso/gans-thesis repo into /content/code using git clone.\n",
    "For more info see: https://medium.com/@purba0101/how-to-clone-private-github-repo-in-google-colab-using-ssh-77384cfef18f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65fc44e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# github.com:22 SSH-2.0-babeld-4cec2db4\n",
      "Warning: Permanently added the RSA host key for IP address '140.82.121.3' to the list of known hosts.\n",
      "root@github.com: Permission denied (publickey).\n",
      "Cloning into '/workspace/code/gans-thesis'...\n",
      "remote: Enumerating objects: 2400, done.\u001B[K\n",
      "remote: Counting objects: 100% (754/754), done.\u001B[K\n",
      "remote: Compressing objects: 100% (381/381), done.\u001B[K\n",
      "remote: Total 2400 (delta 565), reused 526 (delta 357), pack-reused 1646\u001B[K\n",
      "\u001B[KReceiving objects: 100% (2400/2400), 1.07 MiB | 2.63 MiB/s, done.\n",
      "\u001B[KResolving deltas: 100% (1634/1634), done.\n"
     ]
    }
   ],
   "source": [
    "if is_first_run:\n",
    "    !conda install git -y\n",
    "\n",
    "import os\n",
    "\n",
    "repo_root = '/workspace/code/gans-thesis'\n",
    "ssh_root = '/root/.ssh'\n",
    "!rm -rf \"$repo_root\"\n",
    "!rm -rf \"$ssh_root\"\n",
    "if not os.path.exists(repo_root) and not os.path.exists(f'{repo_root}/requirements.txt'):\n",
    "    # Check that ssh keys exist\n",
    "    assert os.path.exists(f'{drive_root}/GitHub Keys')\n",
    "    id_rsa_abs_drive = f'{drive_root}/GitHub Keys/id_rsa'\n",
    "    id_rsa_pub_abs_drive = f'{id_rsa_abs_drive}.pub'\n",
    "    assert os.path.exists(id_rsa_abs_drive)\n",
    "    assert os.path.exists(id_rsa_pub_abs_drive)\n",
    "    # On first run: Add ssh key in repo\n",
    "    if not os.path.exists(ssh_root) or True:\n",
    "        # Transfer config file\n",
    "        ssh_config_abs_drive = f'{drive_root}/GitHub Keys/config'\n",
    "        assert os.path.exists(ssh_config_abs_drive)\n",
    "        !mkdir -p \"$ssh_root\"\n",
    "        !cp -f \"$ssh_config_abs_drive\" \"$ssh_root/\"\n",
    "        # # Add github.com to known hosts\n",
    "        !ssh-keyscan -t rsa github.com >> \"$ssh_root/known_hosts\"\n",
    "        # Test: !ssh -T git@github.com\n",
    "\n",
    "    # Remove any previous attempts\n",
    "    !rm -rf \"$repo_root\"\n",
    "    !mkdir -p \"$repo_root\"\n",
    "    # Clone repo\n",
    "    !ssh -o StrictHostKeyChecking=no github.com\n",
    "    !git clone git@github.com:achariso/gans-thesis.git \"$repo_root\" -o StrictHostKeyChecking=no\n",
    "    src_root = f'{repo_root}/src'\n",
    "    !rm -rf \"$repo_root\"/report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6501d933",
   "metadata": {},
   "source": [
    "## 1.3) Install pip packages\n",
    "All required files are stored in a requirements.txt files at the repository's root.\n",
    "Use `pip install -r requirements.txt` from inside the dir to install required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e6ba54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/code/gans-thesis\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 2)) (8.0.1)\n",
      "Requirement already satisfied: torch>=1.7.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (1.9.0)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 4)) (0.10.0)\n",
      "Requirement already satisfied: humanize in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 5)) (3.9.0)\n",
      "Requirement already satisfied: matplotlib==3.3.1 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 6)) (3.3.1)\n",
      "Requirement already satisfied: colorlog in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 7)) (5.0.1)\n",
      "Requirement already satisfied: prettytable in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 8)) (2.1.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 9)) (2.24.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 10)) (4.51.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 11)) (1.20.2)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 12)) (8.2.0)\n",
      "Requirement already satisfied: ipython in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 13)) (7.24.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 14)) (1.7.0)\n",
      "Requirement already satisfied: httplib2==0.15.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 15)) (0.15.0)\n",
      "Requirement already satisfied: oauth2client in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 16)) (4.1.3)\n",
      "Requirement already satisfied: google-api-python-client in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 17)) (2.9.0)\n",
      "Requirement already satisfied: pydrive in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 18)) (1.3.1)\n",
      "Requirement already satisfied: tensorboard in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 19)) (2.5.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 20)) (5.4.1)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 21)) (3.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib==3.3.1->-r requirements.txt (line 6)) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib==3.3.1->-r requirements.txt (line 6)) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib==3.3.1->-r requirements.txt (line 6)) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/conda/lib/python3.7/site-packages (from matplotlib==3.3.1->-r requirements.txt (line 6)) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /opt/conda/lib/python3.7/site-packages (from matplotlib==3.3.1->-r requirements.txt (line 6)) (2021.5.30)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.7.0->-r requirements.txt (line 3)) (3.7.4.3)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from cycler>=0.10->matplotlib==3.3.1->-r requirements.txt (line 6)) (1.16.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click->-r requirements.txt (line 2)) (4.5.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from humanize->-r requirements.txt (line 5)) (52.0.0.post20210125)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from prettytable->-r requirements.txt (line 8)) (0.2.5)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->-r requirements.txt (line 9)) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->-r requirements.txt (line 9)) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->-r requirements.txt (line 9)) (2.10)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.7/site-packages (from ipython->-r requirements.txt (line 13)) (0.17.0)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.7/site-packages (from ipython->-r requirements.txt (line 13)) (2.9.0)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.7/site-packages (from ipython->-r requirements.txt (line 13)) (0.2.0)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.7/site-packages (from ipython->-r requirements.txt (line 13)) (0.1.2)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.7/site-packages (from ipython->-r requirements.txt (line 13)) (0.7.5)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.7/site-packages (from ipython->-r requirements.txt (line 13)) (5.0.9)\n",
      "Requirement already satisfied: traitlets>=4.2 in /opt/conda/lib/python3.7/site-packages (from ipython->-r requirements.txt (line 13)) (5.0.5)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.7/site-packages (from ipython->-r requirements.txt (line 13)) (4.8.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from ipython->-r requirements.txt (line 13)) (3.0.17)\n",
      "Requirement already satisfied: parso>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from jedi>=0.16->ipython->-r requirements.txt (line 13)) (0.8.2)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.7/site-packages (from pexpect>4.3->ipython->-r requirements.txt (line 13)) (0.7.0)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.7/site-packages (from traitlets>=4.2->ipython->-r requirements.txt (line 13)) (0.2.0)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from oauth2client->-r requirements.txt (line 16)) (4.7.2)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /opt/conda/lib/python3.7/site-packages (from oauth2client->-r requirements.txt (line 16)) (0.4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /opt/conda/lib/python3.7/site-packages (from oauth2client->-r requirements.txt (line 16)) (0.2.8)\n",
      "Requirement already satisfied: google-auth<2dev,>=1.16.0 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client->-r requirements.txt (line 17)) (1.32.0)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client->-r requirements.txt (line 17)) (0.1.0)\n",
      "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client->-r requirements.txt (line 17)) (3.0.1)\n",
      "Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client->-r requirements.txt (line 17)) (1.30.0)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client->-r requirements.txt (line 17)) (20.9)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client->-r requirements.txt (line 17)) (1.53.0)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.7/site-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client->-r requirements.txt (line 17)) (2021.1)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client->-r requirements.txt (line 17)) (3.17.3)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2dev,>=1.16.0->google-api-python-client->-r requirements.txt (line 17)) (4.2.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard->-r requirements.txt (line 19)) (0.4.4)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard->-r requirements.txt (line 19)) (1.38.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard->-r requirements.txt (line 19)) (3.3.4)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard->-r requirements.txt (line 19)) (2.0.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorboard->-r requirements.txt (line 19)) (0.35.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->-r requirements.txt (line 19)) (0.6.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.7/site-packages (from tensorboard->-r requirements.txt (line 19)) (0.13.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->-r requirements.txt (line 19)) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 19)) (1.3.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 19)) (3.1.1)\n",
      "Requirement already satisfied: cached-property in /opt/conda/lib/python3.7/site-packages (from h5py->-r requirements.txt (line 21)) (1.5.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click->-r requirements.txt (line 2)) (3.4.1)\n",
      "\u001B[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001B[0m\n",
      "Requirement already satisfied: kaggle in /opt/conda/lib/python3.7/site-packages (1.5.12)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.7/site-packages (from kaggle) (2.8.1)\n",
      "Requirement already satisfied: urllib3 in /opt/conda/lib/python3.7/site-packages (from kaggle) (1.25.11)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from kaggle) (2.24.0)\n",
      "Requirement already satisfied: python-slugify in /opt/conda/lib/python3.7/site-packages (from kaggle) (5.0.2)\n",
      "Requirement already satisfied: six>=1.10 in /opt/conda/lib/python3.7/site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from kaggle) (4.51.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.7/site-packages (from kaggle) (2021.5.30)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /opt/conda/lib/python3.7/site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->kaggle) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->kaggle) (3.0.4)\n",
      "\u001B[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%cd \"$repo_root\"\n",
    "!pip install -r requirements.txt\n",
    "!pip install kaggle --upgrade\n",
    "\n",
    "# import os\n",
    "# os.kill(os.getpid(), 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706a128d",
   "metadata": {},
   "source": [
    "## 1.4) Add code/, */src/ to path\n",
    "This is necessary in order to be able to run the modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec0bea48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYTHONPATH=\"/env/python:/workspace/code/gans-thesis:/workspace/code/gans-thesis/src\"\n"
     ]
    }
   ],
   "source": [
    "content_root_abs = f'{repo_root}'\n",
    "src_root_abs = f'{repo_root}/src'\n",
    "%env PYTHONPATH=\"/env/python:$content_root_abs:$src_root_abs\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f354c76d",
   "metadata": {},
   "source": [
    "# 2) Train StyleGAN model on DeepFashion's Fashion Image Synthesis Benchmark dataset\n",
    "In this section we run the actual training loop for StyleGAN network. StyleGAN consists of a stylized generator and a\n",
    "fairly naive discriminator architecture. Both however are progressively grown, starting from a resolution of 4x4 up to\n",
    "the final resolution fo 128x128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae078ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "chkpt_step = 'latest'  # supported: 'latest', <int>, None\n",
    "log_level = 'debug'    # supported: 'debug', 'info', 'warning', 'error', 'critical', 'fatal'\n",
    "device = 'cuda'        # supported: 'cpu', 'cuda', 'cuda:<GPU_INDEX>'\n",
    "\n",
    "# Running with -i enables us to get variables defined inside the script (the script runs inline)\n",
    "%run -i src/train_setup.py --log_level $log_level --chkpt_step $chkpt_step --seed 42 --device $device -use_refresh_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a8cce6",
   "metadata": {},
   "source": [
    "## Download dataset from Kaggle instead of Google Drive\n",
    "This results in much much faster download times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649c602c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_first_run:\n",
    "    !conda install unzip -y\n",
    "if not os.path.exists(f'{drive_root}/Datasets/DeepFashion/Fashion Synthesis Benchmark/Img.h5'):\n",
    "    !cp -rf /workspace/kaggle.json /root/.kaggle/\n",
    "    !chmod 600 /root/.kaggle/kaggle.json\n",
    "    !kaggle datasets download achariso/deepfashion-fisb\n",
    "    !rm -rf \"$drive_root\"/Datasets/DeepFashion/Fashion\\ Synthesis\\ Benchmark\n",
    "    !mkdir -p \"$drive_root\"/Datasets/DeepFashion/Fashion\\ Synthesis\\ Benchmark\n",
    "    !unzip /workspace/deepfashion-fisb.zip -d \"$drive_root\"/Datasets/DeepFashion/Fashion\\ Synthesis\\ Benchmark/\n",
    "    !rm -rf /workspace/deepfashion-fisb.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0310e7f",
   "metadata": {},
   "source": [
    "### StyleGAN Training\n",
    "\n",
    "Eventually, run the code!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33accc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd 'src/'\n",
    "\n",
    "import torch\n",
    "from IPython.core.display import display\n",
    "from PIL import Image\n",
    "from torch import Tensor\n",
    "from torch.nn import DataParallel\n",
    "# noinspection PyProtectedMember\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "from datasets.deep_fashion import FISBDataset, FISBDataloader\n",
    "from modules.stylegan import StyleGan\n",
    "from tqdm import tqdm\n",
    "from utils.dep_free import get_tqdm\n",
    "from utils.ifaces import FilesystemDataset\n",
    "from utils.metrics import GanEvaluator\n",
    "\n",
    "###################################\n",
    "###  Hyper-parameters settings  ###\n",
    "###################################\n",
    "#   - training\n",
    "n_epochs = 300\n",
    "batch_size = 128 if not run_locally else 4\n",
    "train_test_splits = [90, 10]  # for a 90% training - 10% evaluation set split\n",
    "#   - evaluation\n",
    "metrics_n_samples = 1000 if not run_locally else 2\n",
    "metrics_batch_size = 32 if not run_locally else 1\n",
    "f1_k = 3 if not run_locally else 1\n",
    "#   - visualizations / checkpoints steps\n",
    "display_steps = {4: 40, 8: 80, 16: 120, 32: 160, 64: 200, 128: 200}\n",
    "checkpoint_steps = {k:3*v for k,v in display_steps.items()}\n",
    "metrics_step = {k:3*v for k,v in checkpoint_steps.items()}  # evaluate model every 3 checkpoints\n",
    "#   - dataset\n",
    "target_shape = 128\n",
    "target_channels = 3\n",
    "#   - StyleGAN configuration\n",
    "z_dim = 512\n",
    "use_half_precision = False\n",
    "stgan_config_id = f'default_z{z_dim}' if not use_half_precision \\\n",
    "    else f'default_z{z_dim}_half'\n",
    "\n",
    "###################################\n",
    "###   Dataset Initialization    ###\n",
    "###################################\n",
    "#   - image transforms:\n",
    "#     If target_shape is different from load one, resize & crop. If target_shape is different from load shape,\n",
    "#     convert to grayscale.\n",
    "#     Update: Now done automatically if you set target_channels, target_shape when instantiating the dataloader.\n",
    "gen_transforms = FISBDataset.get_image_transforms(target_shape=target_shape, target_channels=target_channels)\n",
    "#   - the dataloader used to access the training dataset of cross-scale/pose image pairs at every epoch\n",
    "#     > len(dataloader) = <number of batches>\n",
    "#     > len(dataloader.dataset) = <number of total dataset items>\n",
    "dataloader = FISBDataloader(dataset_fs_folder_or_root=datasets_groot, batch_size=batch_size, log_level=log_level,\n",
    "                            image_transforms=gen_transforms, splits=train_test_splits, pin_memory=not run_locally,\n",
    "                            load_in_memory=False)\n",
    "dataset = dataloader.dataset  # save training dataset as `dataset`\n",
    "#   - ensure dataset is fetched locally and unzipped\n",
    "if isinstance(dataset, FilesystemDataset):\n",
    "    dataset.fetch_and_unzip(in_parallel=False, show_progress=True)\n",
    "elif hasattr(dataset, 'dataset') and isinstance(dataset.dataset, FilesystemDataset):\n",
    "    dataset.dataset.fetch_and_unzip(in_parallel=False, show_progress=True)\n",
    "else:\n",
    "    raise TypeError('dataset must implement utils.ifaces.FilesystemDataset in order to be auto-downloaded and unzipped')\n",
    "#   - apply rudimentary tests\n",
    "assert issubclass(dataloader.__class__, DataLoader)\n",
    "assert len(dataloader) == len(dataset) // batch_size + (1 if len(dataset) % batch_size else 0)\n",
    "_real = next(iter(dataloader))\n",
    "assert tuple(_real.shape) == (batch_size, target_channels, target_shape, target_shape)\n",
    "\n",
    "###################################\n",
    "###    Models Initialization    ###\n",
    "###################################\n",
    "#   - initialize evaluator instance (used to run GAN evaluation metrics: FID, IS, PRECISION, RECALL, F1 and SSIM)\n",
    "evaluator = GanEvaluator(model_fs_folder_or_root=models_groot, gen_dataset=dataset, z_dim=z_dim, device=exec_device,\n",
    "                         n_samples=metrics_n_samples, batch_size=metrics_batch_size, f1_k=f1_k)\n",
    "#   - initialize model\n",
    "chkpt_step = args.chkpt_step\n",
    "try:\n",
    "    if chkpt_step == 'latest':\n",
    "        stgan_chkpt_step = chkpt_step\n",
    "    elif isinstance(chkpt_step, str) and chkpt_step.isdigit():\n",
    "        stgan_chkpt_step = int(chkpt_step)\n",
    "    else:\n",
    "        stgan_chkpt_step = None\n",
    "except NameError:\n",
    "    stgan_chkpt_step = None\n",
    "stgan = StyleGan(model_fs_folder_or_root=models_groot, config_id=stgan_config_id, dataset_len=len(dataset),\n",
    "                 chkpt_epoch=stgan_chkpt_step, evaluator=evaluator, device=exec_device, log_level=log_level)\n",
    "stgan.logger.debug(f'Using device: {str(exec_device)}')\n",
    "stgan.logger.debug(f'Model initialized. Number of params = {stgan.nparams_hr}')\n",
    "# FIX: Warmup counters before first batch\n",
    "if stgan.step is None:\n",
    "    stgan.gforward(batch_size=batch_size)\n",
    "    stgan.logger.debug(f'Model warmed-up (internal counters).')\n",
    "# FIX: Dataloader batch_size need update\n",
    "if stgan.current_batch_size is not None and stgan.current_batch_size != batch_size:\n",
    "    stgan.logger.debug(f'Updating Dataloader batch_size (from {batch_size} --> {stgan.current_batch_size}).')\n",
    "    batch_size = stgan.current_batch_size\n",
    "    dataloader = dataloader.update_batch_size(batch_size=batch_size)\n",
    "#   - setup multi-GPU training\n",
    "if torch.cuda.device_count() > 1:\n",
    "    stgan.gen = DataParallel(stgan.gen)\n",
    "    stgan.info(f'Using {torch.cuda.device_count()} GPUs for StyleGAN Generator (via torch.nn.DataParallel)')\n",
    "#   - load dataloader state (from model checkpoint)\n",
    "if 'dataloader' in stgan.other_state_dicts.keys():\n",
    "    dataloader.set_state(stgan.other_state_dicts['dataloader'])\n",
    "    stgan.logger.debug(f'Loaded dataloader state! Current pem_index={dataloader.get_state()[\"perm_index\"]}')\n",
    "\n",
    "# FIX: Change batch size (if needed)\n",
    "stgan.update_batch_size(batch_size, sampler_instance=dataloader.sampler)\n",
    "\n",
    "###################################\n",
    "###       Training Loop         ###\n",
    "###################################\n",
    "#   - get the correct tqdm instance\n",
    "exec_tqdm = get_tqdm()\n",
    "#   - start training loop from last checkpoint's epoch and step\n",
    "torch.cuda.empty_cache()\n",
    "gcapture_ready = True\n",
    "async_results = None\n",
    "stgan.logger.info(f'[training loop] STARTING (epoch={stgan.epoch}, step={stgan.initial_step})')\n",
    "for epoch in range(stgan.epoch, n_epochs):\n",
    "    # Check if the networks should grow\n",
    "    if stgan.growing() or batch_size != stgan.current_batch_size:\n",
    "        batch_size = stgan.current_batch_size\n",
    "        stgan.logger.critical(f'Reinitializing Dataloader... (new batch_size={batch_size})')\n",
    "        dataloader = dataloader.update_batch_size(batch_size=batch_size)\n",
    "        stgan.update_batch_size(batch_size, sampler_instance=dataloader.sampler)\n",
    "    \n",
    "    # Set steps\n",
    "    display_step = display_steps[stgan.gen.resolution]\n",
    "    checkpoint_step = checkpoint_steps[stgan.gen.resolution]\n",
    "    metrics_step = metrics_steps[stgan.gen.resolution]\n",
    "\n",
    "    # noinspection PyProtectedMember\n",
    "    d = {\n",
    "        'step': stgan.step,\n",
    "        'initial_step': stgan.initial_step,\n",
    "        'epoch': stgan.epoch,\n",
    "        '_counter': stgan._counter,\n",
    "        'epoch_inc': stgan.epoch_inc,\n",
    "    }\n",
    "    # initial_step = stgan.initial_step % len(dataloader)\n",
    "    stgan.logger.debug('[START OF EPOCH] ' + str(d))\n",
    "\n",
    "    # Instantiate progress bart\n",
    "    progress_bar: tqdm = exec_tqdm(dataloader, initial=stgan.initial_step)\n",
    "    progress_bar.set_description(f'[e {str(epoch).zfill(3)}/{str(n_epochs).zfill(3)}]' +\n",
    "                                 f'[g --.-- | d --.--]')\n",
    "\n",
    "    real: Tensor\n",
    "    for real in progress_bar:\n",
    "        # Downsample images\n",
    "        if real.shape[-1] != stgan.gen.resolution:\n",
    "            real = transforms.Resize(size=stgan.gen.resolution, interpolation=Image.BILINEAR)(real)\n",
    "\n",
    "        # Transfer image batches to GPU\n",
    "        real = real.to(exec_device)\n",
    "\n",
    "        # Perform a forward + backward pass + weight update on the Generator & Discriminator models\n",
    "        disc_loss, gen_loss = stgan(real)\n",
    "\n",
    "        # Update loss in tqdm description\n",
    "        if gen_loss is not None and disc_loss is not None:\n",
    "            progress_bar.set_description(f'[e {str(epoch).zfill(3)}/{str(n_epochs).zfill(3)}]' +\n",
    "                                         f'[g {round(gen_loss.item(), 2)} | d {round(disc_loss.item(), 2)}]')\n",
    "\n",
    "        # Metrics & Checkpoint Code\n",
    "        if stgan.step % checkpoint_step == 0:\n",
    "            # Check if another upload is pending\n",
    "            if not gcapture_ready and async_results:\n",
    "                # Wait for previous upload to finish\n",
    "                stgan.logger.warning('Waiting for previous gcapture() to finish...')\n",
    "                [r.wait() for r in async_results]\n",
    "                stgan.logger.warning('DONE! Starting new capture now.')\n",
    "            # Capture current model state, including metrics and visualizations\n",
    "            async_results = stgan.gcapture(checkpoint=True, metrics=stgan.step % metrics_step == 0, visualizations=True,\n",
    "                                           dataloader=dataloader, in_parallel=True, show_progress=True,\n",
    "                                           delete_after=True)\n",
    "        # Visualization code\n",
    "        elif stgan.step % display_step == 0:\n",
    "            visualization_img = stgan.visualize()\n",
    "            visualization_img.show() if not in_notebook() else display(visualization_img)\n",
    "\n",
    "        # Check if a pending checkpoint upload has finished\n",
    "        if async_results:\n",
    "            gcapture_ready = all([r.ready() for r in async_results])\n",
    "            if gcapture_ready:\n",
    "                stgan.logger.info(f'gcapture() finished')\n",
    "                if stgan.latest_checkpoint_had_metrics:\n",
    "                    stgan.logger.info(str(stgan.latest_metrics))\n",
    "                async_results = None\n",
    "\n",
    "        # If run locally one pass is enough\n",
    "        if run_locally and gcapture_ready:\n",
    "            break\n",
    "\n",
    "    # If run locally one pass is enough\n",
    "    if run_locally:\n",
    "        break\n",
    "\n",
    "    # noinspection PyProtectedMember\n",
    "    d = {\n",
    "        'step': stgan.step,\n",
    "        'initial_step': stgan.initial_step,\n",
    "        'epoch': stgan.epoch,\n",
    "        '_counter': stgan._counter,\n",
    "        'epoch_inc': stgan.epoch_inc,\n",
    "    }\n",
    "    stgan.logger.debug('[END OF EPOCH] ' + str(d))\n",
    "\n",
    "# Check if a pending checkpoint exists\n",
    "if async_results:\n",
    "    ([r.wait() for r in async_results])\n",
    "    stgan.logger.info(f'last gcapture() finished')\n",
    "    if stgan.latest_checkpoint_had_metrics:\n",
    "        stgan.logger.info(str(stgan.latest_metrics))\n",
    "    async_results = None\n",
    "\n",
    "# Training finished!\n",
    "stgan.logger.info('[training loop] DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8f5f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kaggle --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba31f0b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}