from math import exp
from typing import Optional, Union

import torch
import torch.nn as nn
import torch.nn.functional as functional
from torch import Tensor
from torch.autograd import Variable
# noinspection PyProtectedMember
from torch.utils.data import Dataset, DataLoader
from torchvision.transforms import transforms
from tqdm import tqdm

from dataset.deep_fashion import ICRBCrossPoseDataset
from modules.generators.pgpg import PGPGGenerator


def _ssim_map(img1: Tensor, img2: Tensor, window, window_size, c_img) -> Tensor:
    """
    Function to calculate the SSIM difference maps between two (batches of) images.
    :param img1: the 1st image batch (real image or perfect reconstruction)
    :param img2: the 2nd image batch (real image or perfect reconstruction)
    :param window:
    :param window_size:
    :param c_img:
    :return:
    """
    padding = window_size // 2
    mu1 = functional.conv2d(img1, window, padding=padding, groups=c_img)
    mu2 = functional.conv2d(img2, window, padding=padding, groups=c_img)

    mu1_sq = mu1.pow(2)
    mu2_sq = mu2.pow(2)
    mu1_mu2 = mu1 * mu2

    sigma1_sq = functional.conv2d(img1 * img1, window, padding=padding, groups=c_img) - mu1_sq
    sigma2_sq = functional.conv2d(img2 * img2, window, padding=padding, groups=c_img) - mu2_sq
    sigma12 = functional.conv2d(img1 * img2, window, padding=padding, groups=c_img) - mu1_mu2

    c_1 = 0.01 ** 2
    c_2 = 0.03 ** 2
    ssim_map = ((2 * mu1_mu2 + c_1) * (2 * sigma12 + c_2)) / ((mu1_sq + mu2_sq + c_1) * (sigma1_sq + sigma2_sq + c_2))
    return ssim_map


def _ssim(img1: Tensor, img2: Tensor, window, window_size, c_img, size_average=True) -> Tensor:
    """
    Function to calculate the SSIM index between two batches of images
    :param img1:
    :param img2:
    :param window:
    :param window_size:
    :param c_img:
    :param size_average:
    :return:
    """
    ssim_map = _ssim_map(img1, img2, window, window_size, c_img)
    return ssim_map.mean() if size_average else ssim_map.mean(1).mean(1).mean(1)


class SSIM(nn.Module):
    """
    SSIM Class:
    This class is used to compute the Structural Similarity (SSIM) index between two batches of images.
    Source: https://github.com/Po-Hsun-Su/pytorch-ssim
    """

    def __init__(self, n_samples: int = 512, batch_size: int = 8, device: str = 'cpu', c_img: int = 3,
                 window_size: int = 11, size_average: bool = True):
        """
        SSIM class constructor:
        :param n_samples: the total number of samples used to compute the metric (defaults to 512; the higher this
                          number gets, the more accurate the metric is)
        :param batch_size: the number of samples to precess at each loop
        :param device: device to run computation on (defaults to 'cpu')
        :param c_img: number of image channels (defaults to 3 for RGB images)
        :param window_size: SSIM window size parameter (kernel size of Conv2d filters)
        :param size_average: SSIM size average flag (set to True to output a scalar value of SSIM index)
        """
        super(SSIM, self).__init__()

        # Create convolution kernel (a multivariate gaussian)
        self.window = SSIM._create_window(window_size, c_img)
        self.window.to(device)

        # Save arguments to instance
        self.window_size = window_size
        self.c_img = c_img
        self.size_average = size_average
        self.n_samples = n_samples
        self.batch_size = batch_size
        self.device = device

    @staticmethod
    def _gaussian(window_size: int, sigma: float) -> Tensor:
        gauss = torch.Tensor([exp(-(x - window_size // 2) ** 2 / float(2 * sigma ** 2)) for x in range(window_size)])
        return gauss / gauss.sum()

    @staticmethod
    def _create_window(window_size: int, c_img: int, gaussian_sigma: float = 1.5) -> Variable:
        _1D_window = SSIM._gaussian(window_size, gaussian_sigma).unsqueeze(1)
        _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)
        return Variable(_2D_window.expand(c_img, 1, window_size, window_size).contiguous())

    # noinspection DuplicatedCode
    def forward(self, dataset: Dataset, gen: nn.Module, target_index: Optional[int] = None,
                condition_indices: Optional[Union[int, tuple]] = None, z_dim: Optional[int] = None) -> float:
        """
        Compute the Inception Score of the images generated by the given generator network.
        :param dataset: a torch.utils.data.Dataset object to access real images as inputs to the Generator
        :param gen: the Generator network
        :param target_index: NOT used in IS
        :param condition_indices: indices of images that will be passed to the Generator in order to generate fake
                                  images (for image-to-image translation tasks). If set to None, the generator is fed
                                  with random noise.
        :param z_dim: if $condition_indices$ is None, then this is necessary to produce random noise to feed into the
                      DCGAN-like generator
        :return: a scalar value with the computed IS
        """
        dataloader = DataLoader(dataset=dataset, batch_size=self.batch_size, shuffle=True)

        cur_samples = 0
        ssim_maps_list = []
        for real_samples in tqdm(dataloader, total=self.n_samples // self.batch_size):
            if cur_samples >= self.n_samples:
                break

            # Get target (real) images
            target_output = real_samples[target_index] if target_index is not None else real_samples
            target_output = target_output.to(self.device)
            cur_batch_size = len(target_output)

            # Generate fake images from conditions
            gen_inputs = [real_samples[_i] for _i in condition_indices] if condition_indices is not None else \
                torch.randn(cur_batch_size, z_dim)
            gen_inputs = [gen_input.to(self.device) for gen_input in gen_inputs] if condition_indices is not None \
                else gen_inputs.to(self.device)
            fake_output = gen(*gen_inputs)
            if type(fake_output) == tuple or type(fake_output) == list:
                fake_output = fake_output[-1]

            # Compute SSIM difference maps
            ssim_maps_list.append(_ssim_map(target_output, fake_output, self.window, self.window_size, self.c_img))
            cur_samples += cur_batch_size

        # Compute SSIM from difference maps
        ssim_maps = torch.cat(ssim_maps_list, dim=0)
        return ssim_maps.mean() if self.size_average else ssim_maps.mean(1).mean(1).mean(1)


if __name__ == '__main__':
    ssim_calculator = SSIM(n_samples=2, batch_size=1, device='cpu')
    _dataset = ICRBCrossPoseDataset(image_transforms=transforms.Compose([transforms.ToTensor()]), pose=True)
    _gen = PGPGGenerator(c_in=6, c_out=3)
    ssim_score = ssim_calculator(_dataset, _gen, target_index=1, condition_indices=(0, 2))
    print(ssim_score)
